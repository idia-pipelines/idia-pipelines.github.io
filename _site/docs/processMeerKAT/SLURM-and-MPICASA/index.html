<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  

  <title>SLURM and MPICASA - IDIA Pipelines</title>
  <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css">
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000/" class="site-title fs-6 lh-tight">IDIA Pipelines</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav role="navigation" aria-label="Main navigation">
  <ul class="navigation-list">
    
    
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/" class="navigation-list-link">Home</a>
            
          </li>
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/access/" class="navigation-list-link">Access to IDIA Machines</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/docs/processMeerKAT" class="navigation-list-link">processMeerKAT</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Quick-Start/" class="navigation-list-link">Quick Start</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Release-Notes/" class="navigation-list-link">Release Notes</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/using-the-pipeline/" class="navigation-list-link">Using the Pipeline</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Example-Use-Cases/" class="navigation-list-link">Example Use Cases</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Diagnosing-Errors/" class="navigation-list-link">Diagnosing Errors</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/config-files/" class="navigation-list-link">Configuration Files</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/cross-calibration-in-processmeerkat/" class="navigation-list-link">Cross-calibration in processMeerKAT</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/self-calibration-in-processmeerkat/" class="navigation-list-link">Self-calibration in processMeerKAT</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/science-imaging-in-processmeerkat/" class="navigation-list-link">Science Imaging in processMeerKAT</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/deep-2-tutorial/" class="navigation-list-link">DEEP 2 Tutorial</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Advanced-Usage/" class="navigation-list-link">Advanced Usage</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item  active">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/SLURM-and-MPICASA/" class="navigation-list-link active">SLURM and MPICASA</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/LICENSE/" class="navigation-list-link">LICENSE</a>
                      
                    </li>
                  
                
              </ul>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/containers/" class="navigation-list-link">Singularity Containers</a>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search IDIA Pipelines" aria-label="Search IDIA Pipelines" autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="//github.com/idia-astro/pipelines/wiki">IDIA Pipelines</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content js-main-content" tabindex="0">
        
          
            <nav class="breadcrumb-nav">
              <ol class="breadcrumb-nav-list">
                
                  <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/processMeerKAT">processMeerKAT</a></li>
                
                <li class="breadcrumb-nav-list-item"><span>SLURM and MPICASA</span></li>
              </ol>
            </nav>
          
        
        <div id="main-content" class="page-content" role="main">
          <h1 id="parallel-casa-using-slurm-at-idia">Parallel CASA Using SLURM at IDIA</h1>

<p><strong>Note: For details on how to setup SLURM batch and interactive jobs on the ilifu system, please look at the <a href="https://docs.ilifu.ac.za/#/getting_started/submit_job_slurm">ilifu documentation</a>.</strong></p>

<p>This page deals with the specifics of using CASA in conjuction with the SLURM environment on the ilifu computing system.</p>

<p>SLURM is a resource and job management system that is available on many clusters. Jobs/tasks are typically submitted to the job management system, and are inserted into a job queue; the job is executed when the requested resources become available. SLURM is the job management and scheduling software used on the ilifu cluster.</p>

<p>While SLURM Clusters provide the option to request and reserve resources to work in an interactive mode, its preferred method is to submit jobs to the queue to be run in a non-interactive way.</p>

<p>To run a CASA script in a non-interactive way in the SLURM cluster, you would use the following steps.</p>

<ol>
  <li>Write your CASA script.</li>
  <li>Write an associated SBATCH script for your job.</li>
  <li>Submit the script (i.e., your job) to the queue using <code class="highlighter-rouge">sbatch</code>.</li>
</ol>

<!---

_**The image below illustrates these different steps.**_

![Basic step-by-step guide on to use SLURM and MPICASA to run a CASA Script.](/assets/slurm-and-mpicasa.png)

--->

<h2 id="write-your-casa-script">Write your CASA Script</h2>

<p>CASA scripts are written in Python. An entire pipeline can be written in such a script, that includes flagging, initial calibration and imaging.</p>

<p>It is important to note that different CASA tasks use different schemes for parallelism, when writing your script. For example, <code class="highlighter-rouge">flagdata</code> parallelises by scan and is thus RAM intensive; <code class="highlighter-rouge">tclean</code> splits up the input data to occupy as many processes as are specified, and is this CPU &amp; RAM intensive.</p>

<p>Therefore, a single script that includes flagging and imaging could have sub-optimal usage of a cluster resources for some tasks, and optimal usage for others. Keep this in mind when writing your script. Here’s an example of a python script that calls tclean in CASA 6:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os,sys
import casampi
from casatasks import tclean,casalog
logfile=casalog.logfile()
casalog.setlogfile('logs/{SLURM_JOB_NAME}-{SLURM_JOB_ID}.casa'.format(**os.environ))

vis=sys.argv[-1]
imagename=vis + '.image'

tclean(vis=vis, imagename=imagename, imsize=[6144,6144], cell='1.5arcsec', gridder='wproject', wprojplanes=512, deconvolver='mfmfs', weighting='briggs',robust=-0.5, niter=50000, threshold=10e-6, nterms=2, pblimit=-1, parallel = True)

if os.path.exists(logfile):
  os.rename(logfile,'logs/{SLURM_JOB_NAME}-{SLURM_JOB_ID}.mpi'.format(**os.environ))
</code></pre></div></div>

<h2 id="write-your-sbatch-script">Write your SBATCH Script</h2>

<p>An SBATCH script is a bash script that wraps the relevant SLURM parameters needed for your script. Consult the following website for more details on how to use SBATCH:
https://slurm.schedmd.com/sbatch.html</p>

<p>Here’s an example of an SBATCH script that submits a <code class="highlighter-rouge">tclean</code> job for CASA 6:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c">#SBATCH --account=b05-pipelines-ag</span>
<span class="c">#SBATCH --nodes=1</span>
<span class="c">#SBATCH --ntasks-per-node=32</span>
<span class="c">#SBATCH --cpus-per-task=1</span>
<span class="c">#SBATCH --mem=232GB</span>
<span class="c">#SBATCH --job-name=tclean</span>
<span class="c">#SBATCH --output=logs/%x-%j.out</span>
<span class="c">#SBATCH --error=logs/%x-%j.err</span>
<span class="c">#SBATCH --partition=Main</span>
<span class="c">#SBATCH --time=03:00:00</span>

<span class="c">#Run the application:</span>
module load openmpi/2.1.1
mpirun singularity <span class="nb">exec</span> /path/to/casa/container.simg python tclean.py /path/to/data.ms
</code></pre></div></div>

<p>More details can be found in the ilifu documentation about <a href="https://docs.ilifu.ac.za/#/getting_started/container_environments">using Singularity</a> and <a href="https://docs.ilifu.ac.za/#/getting_started/submit_job_slurm?id=parallel-computing-on-the-cluster">parallel processing</a>. Some other helpful resources include the <a href="https://docs.ilifu.ac.za/#/tech_docs/resource_allocation">resource allocation guide</a> and the <a href="https://www.ilifu.ac.za/latest-training">ilifu training</a>.</p>

<p>There are a few important SBATCH parameters to define:</p>

<ul>
  <li><code class="highlighter-rouge">--nodes</code> or <code class="highlighter-rouge">-N</code> specifies the node count, i.e., the nodes requested for the job.</li>
  <li><code class="highlighter-rouge">--tasks-per-node</code> specifies the number of parallel tasks to execute on each node.</li>
  <li><code class="highlighter-rouge">--distribution</code> or <code class="highlighter-rouge">-m</code> specifies the mode in which the tasks are distributed to each node.
    <ul>
      <li>This parameter is useful for scripts that include flagging. Since flagging is parallelised by scan, the first node(s) could run out of RAM for a particular flagging job. This would lead to SLURM killing the offending task(s), hence killing the main job.</li>
      <li>There are two distribution modes that can be used to solve this problem. <code class="highlighter-rouge">plane=X</code> distributes X jobs at a time, in a round-robin fashion across nodes. The <code class="highlighter-rouge">cyclic</code> mode distributes single tasks at a time in a round-robin fashion across nodes.</li>
      <li><code class="highlighter-rouge">plane=X</code> or <code class="highlighter-rouge">cyclic</code> modes are useful for jobs that are RAM limited, i.e., when you need to use the aggregated RAM that’s in the total pool requested.
<!-- - The `-J`, `-o` and `-e` parameters --></li>
    </ul>
  </li>
</ul>

<h3 id="more-about-slurm">More about SLURM</h3>
<p><a href="https://slurm.schedmd.com/overview.html">SLURM</a> is a workload manager that will distribute jobs across a specified cluster environment. It understands how to control message passing interface (MPI) jobs across multiple tasks (or nodes) via <code class="highlighter-rouge">mpirun</code> and for CASA 5, <code class="highlighter-rouge">mpicasa</code>. In principle this means that SLURM should be able to schedule and manage a CASA job that is running across a cluster.</p>

<p>Following is a “practical” definition of some SLURM keywords that should help clarify how to best to allocate resources.</p>

<p><strong>task</strong> : A “task” by SLURM’s definition is what one would usually call a “process” on a regular computer. Similar to a process, a task has its own memory allocation that it does not share with other tasks. Each task is then operated on independently via MPI. This also means a more <em>fine-grained</em> parallelism can be employed per task, by using multiple threads (<em>e.g.</em> via OpenMP) to work on a single task.</p>

<p><strong>–cpus-per-task</strong> : Defines the number of CPUs to dedicate to a single task. If each task can take advantage of multiple threads, setting this value to more than one can speed things up further (<em>e.g.,</em> <code class="highlighter-rouge">tclean</code> in CASA is parallelised across OpenMP and MPI)</p>

<p><strong>–mem-per-cpu</strong> : The RAM dedicated to each CPU in the node. Currently, the ilifu cluster is set to 3096 MB per CPU. If a job is running out of memory, setting this to a larger value can help. Alternatively, as mentioned above, if the task can take advantage of more threads, it may be preferable to set <code class="highlighter-rouge">--cpus-per-task</code> instead.</p>

<!-- __-m/--distribution__ : This controls how the tasks are allocated across the requested nodes. The sbatch `man` page has a very good explanation on the various modes available. -->

<hr />

<h3 id="notes-on-casa-tasks-and-parallelism">Notes on CASA Tasks and Parallelism</h3>

<p>Running CASA through SLURM requires calling CASA via <code class="highlighter-rouge">mpirun</code>, or for CASA 5, <code class="highlighter-rouge">mpicasa</code>. CASA understands how to use <code class="highlighter-rouge">mpi</code> on tasks that are optimised for <code class="highlighter-rouge">mpi</code> (such as <code class="highlighter-rouge">flagdata</code>, <code class="highlighter-rouge">tclean</code>, <code class="highlighter-rouge">setjy</code>, and <code class="highlighter-rouge">applycal</code>) while operating as per usual on tasks that are not <code class="highlighter-rouge">mpi</code> aware (like <code class="highlighter-rouge">gaincal</code>). Ideally, the only change to an existing script would be to add a call to <code class="highlighter-rouge">partition</code> (or <code class="highlighter-rouge">mstransform(createmms=True)</code>) at the top. Below are some notes on tasks.</p>

<p><strong>partition</strong> (basic): In order to run tasks (except tclean) across a cluster, the <code class="highlighter-rouge">partition</code> (or <code class="highlighter-rouge">mstransform</code>) task needs to be called prior to running any other tasks. <code class="highlighter-rouge">partition</code>  <a href="https://casa.nrao.edu/casadocs/casa-5.4.1/uv-manipulation/data-partition">creates a multi-measurement set</a> (MMS) that is a collection of multiple sub-MSs, each of which will be operated upon as a task in SLURM. By default, CASA will split the MS across scans, and a spectral window (<code class="highlighter-rouge">spw</code>) axis, given by the default <code class="highlighter-rouge">separationaxis='auto'</code> parameter. However, this partitioning of data gives a data format that does not appear to perform well during processing. A better partitioning of the data is given by simply partitioning by scan, given by <code class="highlighter-rouge">separationaxis='scan', numsubms=msmd.nscans()</code></p>

<p><strong>mstransform</strong> (advanced): the <code class="highlighter-rouge">mstransform</code> task (called under the hood by <code class="highlighter-rouge">partition</code>) is better suited to partition an MS into an MMS, as it allows for more control via several additional parameters, such as averaging in time and frequency. For example, the following call averages by 8 frequency channels (from selected frequency range 880-1680 MHz) and 16 second integrations, as well as selecting only two (parallel-hand) correlations (controlled by one core each, given by <code class="highlighter-rouge">nthreads=2</code>), and no autocorrelations:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mstransform(vis=visname, outputvis=mvis, spw='*:880~1680MHz', createmms=True, datacolumn='DATA', chanaverage=True, chanbin=8, timeaverage=True, timebin='16s', separationaxis='scan', numsubms=msmd.nscans(), nthreads=2, antenna='*&amp;', correlation='XX,YY')
</code></pre></div></div>

<!--
The number of SUBMSes created can be specified in `partition`, however it seems that specifying a number larger than what CASA would decide leads to some strangeness with the metadata (and a failure of tasks that operate on the MMS).
-->

<p><strong>tclean</strong>: In order to run across a cluster, <code class="highlighter-rouge">parallel=True</code> should be specified in <code class="highlighter-rouge">tclean</code>. However, if <code class="highlighter-rouge">savemodel='modelcolumn'</code> is also specified, it triggers some kind of a race condition between the different nodes where they are competing for write access, and the task crashes. So setting <code class="highlighter-rouge">savemodel='virtual'</code> or <code class="highlighter-rouge">savemodel='none'</code> are the only options that work when running <code class="highlighter-rouge">tclean</code> in parallel. Both the <code class="highlighter-rouge">makePSF</code> step and the major cycles of deconvolution are MPI and OpenMP aware, and can exploit additional resources specified via <code class="highlighter-rouge">--cpus-per-task</code> in the SLURM <code class="highlighter-rouge">sbatch</code> file.</p>


          
        </div>
      </div>
    </div>
  </div>

</body>
</html>
