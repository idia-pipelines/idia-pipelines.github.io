<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  

  <title>DEEP 2 Tutorial - IDIA Pipelines</title>
  <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css">
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000/" class="site-title fs-6 lh-tight">IDIA Pipelines</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav role="navigation" aria-label="Main navigation">
  <ul class="navigation-list">
    
    
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/" class="navigation-list-link">Home</a>
            
          </li>
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/access/" class="navigation-list-link">Access to IDIA Machines</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/docs/processMeerKAT" class="navigation-list-link">processMeerKAT</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Release-Notes/" class="navigation-list-link">Release Notes</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Using-The-Pipeline/" class="navigation-list-link">Using the Pipeline</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Example-Use-Cases/" class="navigation-list-link">Example Use Cases</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Diagnosing-Errors/" class="navigation-list-link">Diagnosing Errors</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item  active">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/DEEP-2-Tutorial/" class="navigation-list-link active">DEEP 2 Tutorial</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Calibration-in-processMeerKAT/" class="navigation-list-link">Calibration in ProcessMeerKAT</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/SLURM-and-MPICASA/" class="navigation-list-link">SLURM and MPICASA</a>
                      
                    </li>
                  
                
              </ul>
            
          </li>
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/containers/" class="navigation-list-link">Singularity Containers</a>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search IDIA Pipelines" aria-label="Search IDIA Pipelines" autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="//github.com/idia-astro/pipelines/wiki">IDIA Pipelines</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content js-main-content" tabindex="0">
        
          
            <nav class="breadcrumb-nav">
              <ol class="breadcrumb-nav-list">
                
                  <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/processMeerKAT">processMeerKAT</a></li>
                
                <li class="breadcrumb-nav-list-item"><span>DEEP 2 Tutorial</span></li>
              </ol>
            </nav>
          
        
        <div id="main-content" class="page-content" role="main">
          <h1 id="deep-2-tutorial">DEEP 2 Tutorial</h1>

<h4 id="this-tutorial-walks-you-through-running-the-various-steps-of-the-pipeline-for-a-single-deep-2-dataset-which-is-a-16-dish-4k-mode-meerkat-observation-of-a-random-patch-of-sky-11-gb-in-size">This tutorial walks you through running the various steps of the pipeline for a single DEEP 2 dataset, which is a 16 dish, 4k-mode MeerKAT observation of a random patch of sky, 11 GB in size.</h4>

<p>To begin, ssh into the ilifu cluster (<code class="highlighter-rouge">slurm.ilifu.ac.za</code>), and create a working directory somewhere on the filesystem (e.g. <code class="highlighter-rouge">/ceph/pipelines/your_username/tutorial/</code>).</p>

<h5 id="1-source-setupsh-which-will-add-to-your-path-and-pythonpath">1. Source <code class="highlighter-rouge">setup.sh</code>, which will add to your PATH and PYTHONPATH</h5>

<p><code class="highlighter-rouge">source /data/exp_soft/pipelines/master/setup.sh</code></p>

<h5 id="2-build-a-config-file-using-verbose-mode-and-pointing-to-the-deep-2-dataset">2. Build a config file, using verbose mode, and pointing to the DEEP 2 dataset</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -B -C tutorial_config.txt -M /data/projects/deep/1491550051.ms -v</code></p>

<p>After some initial debug output, you should get the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 02:36:14,421 INFO: Extracting field IDs from measurement set "/data/projects/deep/1491550051.ms" using CASA.
2019-02-28 02:36:14,422 DEBUG: Using the following command:
	srun --nodes=1 --ntasks=1 --time=10 --mem=4GB --partition=Main singularity exec /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg  casa --nologger --nogui --nologfile -c /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/get_fields.py -B -M /data/projects/deep/1491550051.ms -C tutorial_config.txt -N 8 -t 4
		.
		.
		.
2019-02-28 02:37:39,788 WARNING: The number of threads (8 node(s) x 4 task(s) = 32) is not ideal compared to the number of scans (12) for "/data/projects/deep/1491550051.ms".
2019-02-28 02:37:39,788 WARNING: Config file has been updated to use 2 node(s) and 4 task(s) per node.
2019-02-28 02:37:39,788 INFO: For the best results, update your config file so that nodes x tasks per node = 7.
2019-02-28 02:37:40,045 INFO: Multiple fields found with intent "CALIBRATE_FLUX" in dataset "/data/projects/deep/1491550051.ms" - [0 1].
2019-02-28 02:37:40,110 WARNING: Only using field "0" for "fluxfield", which has the most scans (1).
2019-02-28 02:37:40,110 WARNING: Putting extra fields with intent "CALIBRATE_FLUX" in "targetfields" - [1]
2019-02-28 02:37:40,111 INFO: Multiple fields found with intent "CALIBRATE_BANDPASS" in dataset "/data/projects/deep/1491550051.ms" - [0 1].
2019-02-28 02:37:40,111 WARNING: Only using field "0" for "bpassfield", which has the most scans (1).
2019-02-28 02:37:40,112 INFO: Multiple fields found with intent "CALIBRATE_PHASE" in dataset "/data/projects/deep/1491550051.ms" - [1 2].
2019-02-28 02:37:40,112 WARNING: Only using field "2" for "phasecalfield", which has the most scans (5).
2019-02-28 02:37:40,123 INFO: [fields] section written to "tutorial_config.txt". Edit this section to change field IDs (comma-seperated string for multiple IDs).
2019-02-28 02:37:41,990 INFO: Config "tutorial_config.txt" generated.
</code></pre></div></div>

<p>This calls CASA via the default singularity container without writing log files, and runs <code class="highlighter-rouge">get_fields.py</code>. It calls <code class="highlighter-rouge">srun</code>, requesting only 1 node, 1 task, 4 GB of memory, and a 10 minute time limit, to increase the likelihood of jumping to the top of the queue. The purpose of this call is to extract the field IDs corresponding to our different targets, and check the nodes and tasks per node against the number of scans, each of which is handled by a thread (see section 3). The output statements with <code class="highlighter-rouge">DEBUG</code> correspond to those output during verbose mode. The warnings display when multiple fields are present with the same intent, but only one is extracted, corresponding to the field with the most scans. In this case the extras are moved to <code class="highlighter-rouge">targetfields</code> (i.e. for applying calibration and imaging).</p>

<h5 id="3-view-the-config-file-created-which-has-the-following-contents">3. View the config file created, which has the following contents:</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[crosscal]
minbaselines = 4                  # Minimum number of baselines to use while calibrating
specavg = 1                       # Number of channels to average after calibration (during split)
timeavg = '8s'                    # Time interval to average after calibration (during split)
keepmms = True                    # Output MMS (True) or MS (False) during split
spw = '0:860~1700MHz'             # Spectral window / frequencies to extract for MMS
calcrefant = True                 # Calculate reference antenna in program (overwrites 'refant')
refant = 'm005'                   # Reference antenna name / number
standard = 'Perley-Butler 2010'   # Flux density standard for setjy
badants = []                      # List of bad antenna numbers (to flag)
badfreqranges = [ '944~947MHz',   # List of bad frequency ranges (to flag)
        '1160~1310MHz',
        '1476~1611MHz',
        '1670~1700MHz']

[slurm]
nodes = 2
ntasks_per_node = 4
plane = 2
mem = 236
partition = 'Main'
time = '12:00:00'
submit = False
container = '/data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg'
mpi_wrapper = '/data/exp_soft/pipelines/casa-prerelease-5.3.0-115.el7/bin/mpicasa'
name = ''
verbose = True
scripts = [('validate_input.py', False, ''), ('partition.py', True, ''), ('calc_refant.py', False, ''), ('flag_round_1.py', True, ''), ('setjy.py', True, ''), ('xx_yy_solve.py', False, ''), ('xx_yy_apply.py', True, ''), ('flag_round_2.py', True, ''), ('setjy.py', True, ''), ('xy_yx_solve.py', False, ''), ('xy_yx_apply.py', True, ''), ('split.py', True, ''), ('quick_tclean.py', True, ''), ('plot_solutions.py', False, '')]

[data]
vis = '/data/projects/deep/1491550051.ms'

[fields]
bpassfield = '0'
fluxfield = '0'
phasecalfield = '2'
targetfields = '3,1'
</code></pre></div></div>

<p>This config file contains four sections - crosscal, slurm, data, and fields. The fields IDs we just extracted, seen in section <code class="highlighter-rouge">[fields]</code>, correspond to field 0 for the bandpass calibrator, field 0 for the total flux calibrator, field 2 for the phase calibrator, and fields 3 and 1 for the science targets (i.e. the DEEP 2 field + another calibrator). Only the target may have multiple fields. If a field isn’t found according to its intent, a warning is displayed, and the field for the total flux calibrator is selected. If the total flux calibrator isn’t present, the program will display an error and terminate.</p>

<p>The SLURM parameters in section <code class="highlighter-rouge">[slurm]</code> correspond to those seen by running <code class="highlighter-rouge">processMeerKAT.py -h</code>. By default, for all threadsafe scripts (i.e. those with <code class="highlighter-rouge">True</code> in the <code class="highlighter-rouge">scripts</code> list), we use 8 nodes, 4 tasks per node (=32 threads), 236 GB of memory (per node), and <code class="highlighter-rouge">plane=2</code> (which distributes four tasks onto one node before moving onto next node). During step 2, only 12 scans were found, and since <code class="highlighter-rouge">partition.py</code> partitions the data into one sub-measurement set (sub-MS) per scan, only 12 sub-MSs will exist in the multi-measurement set (see section 19). Assuming each observation has a phase calibrator bracketing each target scan, at most, 6 sub-MSs will be operated on at any given time, each handled by one thread, and a master thread. So we aim to have a limit of nscans+1+10% threads, with the 10% to account for the occasional thread that hangs. For this dataset, this limit is 7 threads, so <code class="highlighter-rouge">get_fields.py</code> attempts to match this number by using the specified number of tasks per node and increasing the node count from 1 until the number of threads is more than the limit, terminating at 2 nodes x 4 tasks per node = 8 threads.</p>

<p>For script that aren’t threadsafe (i.e. those with <code class="highlighter-rouge">False</code> in the <code class="highlighter-rouge">scripts</code> list), we use a single node, and a single task per node. For both scripts that are threadsafe and those that aren’t, we use a single CPU per task, and explicitly export <code class="highlighter-rouge">OMP_NUM_THREADS=1</code>, since there is little evidence of a speedup with more than one CPU per task. However, for <code class="highlighter-rouge">quick_tclean.py</code> we use 4 CPUs per task.</p>

<p>The cross-calibration parameters in section <code class="highlighter-rouge">[crosscal]</code> correspond to various CASA parameters passed into the calibration tasks that the pipeline used, each of which is documented in [[Calibration-in-processMeerKAT]]. By default all frequency ranges listed in <code class="highlighter-rouge">badfreqranges</code>, and all antenna numbers listed in <code class="highlighter-rouge">badants</code>, will be flagged out entirely. The third script the pipeline runs (<code class="highlighter-rouge">calc_refant.py</code>) will likely change the value of <code class="highlighter-rouge">refant</code>, and add a list of bad antennas to <code class="highlighter-rouge">badant</code>.</p>

<h5 id="4-run-the-pipeline-using-your-config-file">4. Run the pipeline using your config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>You should get the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 02:44:06,078 DEBUG: Copying 'tutorial_config.txt' to '.config.tmp', and using this to run pipeline.
2019-02-28 02:44:06,096 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again
2019-02-28 02:44:06,131 DEBUG: Wrote sbatch file "validate_input.sbatch"
2019-02-28 02:44:06,138 DEBUG: Wrote sbatch file "partition.sbatch"
2019-02-28 02:44:06,144 DEBUG: Wrote sbatch file "calc_refant.sbatch"
2019-02-28 02:44:06,150 DEBUG: Wrote sbatch file "flag_round_1.sbatch"
2019-02-28 02:44:06,156 DEBUG: Wrote sbatch file "setjy.sbatch"
2019-02-28 02:44:06,172 DEBUG: Wrote sbatch file "xx_yy_solve.sbatch"
2019-02-28 02:44:06,247 DEBUG: Wrote sbatch file "xx_yy_apply.sbatch"
2019-02-28 02:44:06,253 DEBUG: Wrote sbatch file "flag_round_2.sbatch"
2019-02-28 02:44:06,260 DEBUG: Wrote sbatch file "setjy.sbatch"
2019-02-28 02:44:06,267 DEBUG: Wrote sbatch file "xy_yx_solve.sbatch"
2019-02-28 02:44:06,273 DEBUG: Wrote sbatch file "xy_yx_apply.sbatch"
2019-02-28 02:44:06,279 DEBUG: Wrote sbatch file "split.sbatch"
2019-02-28 02:44:06,291 DEBUG: Wrote sbatch file "quick_tclean.sbatch"
2019-02-28 02:44:06,331 DEBUG: Wrote sbatch file "plot_solutions.sbatch"
2019-02-28 02:44:06,338 INFO: Master script "submit_pipeline.sh" written, but will not run.
</code></pre></div></div>

<p>A number of sbatch files have now been written to your working directory, each of which corresponds to the python script in the list of scripts set by the <code class="highlighter-rouge">scripts</code> parameter in our config file. Our config file was copied to <code class="highlighter-rouge">.config.tmp</code>, which is the config file written and edited by the pipeline, which the user should not touch. A bash script called <code class="highlighter-rouge">submit_pipeline.sh</code> was written, which we will look at soon. However, this script was not run, since we set <code class="highlighter-rouge">submit = False</code> in our config file (you can change this in your config file, or by using option <code class="highlighter-rouge">[-s --submit]</code> when you build your config file with <code class="highlighter-rouge">processMeerKAT.py</code>). Lastly, a <code class="highlighter-rouge">logs</code> directory was created, which will store the log files from the SLURM output.</p>

<h5 id="5-view-validate_inputsbatch-which-has-the-following-contents">5. View <code class="highlighter-rouge">validate_input.sbatch</code>, which has the following contents:</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c">#SBATCH --nodes=1</span>
<span class="c">#SBATCH --ntasks-per-node=1</span>
<span class="c">#SBATCH --cpus-per-task=1</span>
<span class="c">#SBATCH --mem=100GB</span>
<span class="c">#SBATCH --job-name=validate_input</span>
<span class="c">#SBATCH --distribution=plane=1</span>
<span class="c">#SBATCH --output=logs/validate_input-%j.out</span>
<span class="c">#SBATCH --error=logs/validate_input-%j.err</span>
<span class="c">#SBATCH --partition=Main</span>
<span class="c">#SBATCH --time=12:00:00</span>

<span class="nb">export </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span>1

srun singularity <span class="nb">exec</span> /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg  casa <span class="nt">--nologger</span> <span class="nt">--nogui</span> <span class="nt">--logfile</span> logs/validate_input-<span class="k">${</span><span class="nv">SLURM_JOB_ID</span><span class="k">}</span>.casa <span class="nt">-c</span> /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/validate_input.py <span class="nt">--config</span> .config.tmp
</code></pre></div></div>

<p>Since this script is not threadsafe, the job is called with <code class="highlighter-rouge">srun</code>, and is configured to run a single task on a single node, with 100 GB of memory. The last line shows the CASA call of the <code class="highlighter-rouge">validate_input.py</code> task, which will validate the parameters in the config file.</p>

<h5 id="6-run-the-first-sbatch-job">6. Run the first sbatch job</h5>

<p><code class="highlighter-rouge">sbatch validate_input.sbatch</code></p>

<p>You should see the following output, corresponding to your SLURM job ID</p>

<p><code class="highlighter-rouge">Submitted batch job 1097914</code></p>

<h5 id="7-view-your-job-in-the-slurm-queue">7. View your job in the SLURM queue</h5>

<p><code class="highlighter-rouge">squeue</code></p>

<p>You will see something similar to the following, with other people’s jobs mixed into the queue.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
1097914      Main validate jcollier  R       0:13      1 slwrk-008
</code></pre></div></div>

<p>We can see the job with name <code class="highlighter-rouge">validate</code> was submitted to SLURM worker node 8, amongst a number of jobs in the main partition, the JupyterSpawner partition, and possible other partitions. Your job may list <code class="highlighter-rouge">(Priority)</code>, which means it is too low a priority to be run at this point, or <code class="highlighter-rouge">(Resources)</code>, which means it is waiting for resources to be made available.</p>

<p><em>NOTE: You can view just your jobs with <code class="highlighter-rouge">squeue -u your_username</code>, an individual job with <code class="highlighter-rouge">squeue -j 1097914</code>, and just the jobs in the main partition with <code class="highlighter-rouge">squeue -p Main</code>. You can view which nodes are allocated, which are idle, which are mixed (i.e. partially allocated), and which are down in the main partition with <code class="highlighter-rouge">sinfo -p Main</code>. Often it is good idea to check this before selecting your SLURM parameters.</em></p>

<h5 id="8-view-partitionsbatch-which-has-the-following-contents">8. View <code class="highlighter-rouge">partition.sbatch</code>, which has the following contents:</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c">#SBATCH --nodes=2</span>
<span class="c">#SBATCH --ntasks-per-node=4</span>
<span class="c">#SBATCH --cpus-per-task=1</span>
<span class="c">#SBATCH --mem=236GB</span>
<span class="c">#SBATCH --job-name=partition</span>
<span class="c">#SBATCH --distribution=plane=2</span>
<span class="c">#SBATCH --output=logs/partition-%j.out</span>
<span class="c">#SBATCH --error=logs/partition-%j.err</span>
<span class="c">#SBATCH --partition=Main</span>
<span class="c">#SBATCH --time=12:00:00</span>

<span class="nb">export </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span>1

/data/exp_soft/pipelines/casa-prerelease-5.3.0-115.el7/bin/mpicasa singularity <span class="nb">exec</span> /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg  casa <span class="nt">--nologger</span> <span class="nt">--nogui</span> <span class="nt">--logfile</span> logs/partition-<span class="k">${</span><span class="nv">SLURM_JOB_ID</span><span class="k">}</span>.casa <span class="nt">-c</span> /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/partition.py <span class="nt">--config</span> .config.tmp
</code></pre></div></div>

<p>Here we see the same default SLURM parameters for threadsafe tasks, as discussed in section 3. We now use mpicasa as the mpi wrapper, since we are calling a threadsafe script <code class="highlighter-rouge">partition.py</code>, which calls CASA task <code class="highlighter-rouge">partition</code>, which partitions the data into several sub measurement sets (sub-MSs - see <a href="#View-the-contents-of-1491550051.mms">section 14 below</a>) and selects only frequencies specified by your spectral window with parameter <code class="highlighter-rouge">spw</code> in your config file.</p>

<h5 id="9-submit-your-job-and-watch-it-in-the-queue">9. Submit your job and watch it in the queue</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sbatch partition.sbatch
Submitted batch job 1097917
squeue -j 1097917
</code></pre></div></div>

<p>You will see something similar to the following, showing that 2 nodes are now being used (worker nodes 60 &amp; 61).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
1097917      Main partitio jcollier  R       0:22      2 slwrk-[060-061]
</code></pre></div></div>

<p>Wait until the job completes, before step 10.</p>

<h5 id="10-view-the-contents-of-1491550051mms">10. View the contents of <code class="highlighter-rouge">1491550051.mms</code>.</h5>

<p>You should see two new files - <code class="highlighter-rouge">1491550051.mms</code> and <code class="highlighter-rouge">1491550051.mms.flagversions</code>, which corresponds to the data and flag data of a multi-measurement set (MMS). From now on, the pipeline operates on these data, rather than the . The same path to the original MS will remain in your config file under section <code class="highlighter-rouge">[data]</code>, but each task will point to your MMS.</p>

<p>Inside this MMS, you will find the same tables and metadata as in a normal MS, but you will also see a <code class="highlighter-rouge">SUBMSS</code> directory, which should have the following contents.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1491550051.mms.0000.ms	1491550051.mms.0004.ms	1491550051.mms.0008.ms
1491550051.mms.0001.ms	1491550051.mms.0005.ms	1491550051.mms.0009.ms
1491550051.mms.0002.ms	1491550051.mms.0006.ms	1491550051.mms.0010.ms
1491550051.mms.0003.ms	1491550051.mms.0007.ms	1491550051.mms.0011.ms
</code></pre></div></div>

<p>These are the 12 sub-MSs, partitioned by this observation’s 12 scans of the various targets.</p>

<p>If we now view the CASA log, you will find a bunch of junk output from mpicasa (often including nominal “errors”, sometimes severe), and 13 calls of <code class="highlighter-rouge">partition</code>, corresponding to 12 workers for your 12 sub-MSs, and one master process. Similarly, your standard output logs will contains 8 sets of output from CASA launching, corresponding to the 8 threads (i.e. 2 nodes x 4 tasks per node) and some junk output from mpicasa. Again, your standard error log should be empty.</p>

<h5 id="11-run-calc_refantsbatch-and-watch-your-submitted-job">11. Run <code class="highlighter-rouge">calc_refant.sbatch</code> and watch your submitted job</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sbatch calc_refant.sbatch
watch sacct
</code></pre></div></div>

<p>You will initially see something similar to the following</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       JobID    JobName  Partition    Account  AllocCPUS      State ExitCode
------------ ---------- ---------- ---------- ---------- ---------- --------
1097917       partition       Main b03-pipel+          8  COMPLETED      0:0
1097917.bat+      batch            b03-pipel+          4  COMPLETED      0:0
1097917.0         orted            b03-pipel+          1  COMPLETED      0:0
1097918      calc_refa+       Main b03-pipel+          1    RUNNING      0:0
1097918.0    singulari+            b03-pipel+          1    RUNNING      0:0
</code></pre></div></div>

<p><code class="highlighter-rouge">sacct</code> lists all recently submitted jobs and their status. If your job fails, it will list <code class="highlighter-rouge">FAILED</code> under <code class="highlighter-rouge">State</code>. However, please note jobs running <code class="highlighter-rouge">mpicasa</code> often state they have failed when they haven’t. Similarly, when jobs do genuinely fail, the pipeline may continue to run. Both of these are issues we are working to overcome.</p>

<p>When your job completes, you will see something similar to the following</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       JobID    JobName  Partition    Account  AllocCPUS      State ExitCode
------------ ---------- ---------- ---------- ---------- ---------- --------
1097917       partition     Test02 b03-pipel+          8  COMPLETED      0:0
1097917.bat+      batch            b03-pipel+          4  COMPLETED      0:0
1097917.0         orted            b03-pipel+          1  COMPLETED      0:0
1097918      calc_refa+       Main b03-pipel+          1  COMPLETED      0:0
1097918.bat+      batch            b03-pipel+          1  COMPLETED      0:0
1097918.0    singulari+            b03-pipel+          1  COMPLETED      0:0
</code></pre></div></div>

<p>Control-C to exit out of <code class="highlighter-rouge">watch</code>.</p>

<h5 id="12-view-the-contents-of-your-logs-directory">12. View the contents of your <code class="highlighter-rouge">logs</code> directory</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ls logs
calc_refant-1097918.casa  calc_refant-1097918.err  calc_refant-1097918.out  
partition-1097917.casa  partition-1097917.err  partition-1097917.out  
validate_input-1097914.casa  validate_input-1097914.err  validate_input-1097914.out
</code></pre></div></div>

<p>As specified in our sbatch file, standard out is written to <code class="highlighter-rouge">logs/calc_refant-1097918.out</code>, standard error is written to <code class="highlighter-rouge">logs/calc_refant-1097918.err</code>, and the CASA logs are written to <code class="highlighter-rouge">logs/calc_refant-1097918.casa</code>. Your standard output log and CASA log will have little of interest, but your standard error log will contain the following output:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 03:02:33,870 INFO: Flux field scan no: 1
2019-02-28 03:02:34,034 INFO: Antenna statistics on total flux calibrator
2019-02-28 03:02:34,035 INFO: (flux in Jy averaged over scans &amp; channels, and over all of each antenna's baselines)
2019-02-28 03:02:34,035 INFO: ant median rms
2019-02-28 03:03:10,900 INFO: All 8.92  275.02
2019-02-28 03:03:10,900 INFO: 7   8.10  199.94 (best antenna)
2019-02-28 03:03:10,900 INFO: 0   8.84  305.28 (1st good antenna)
2019-02-28 03:03:10,900 INFO: setting reference antenna to: 7
2019-02-28 03:03:10,900 INFO: Bad antennas: [5, 15]
</code></pre></div></div>

<p>Here we see <code class="highlighter-rouge">calc_refant.py</code> has selected antenna 7 as the best reference antenna, which measures comparable amplitude for the total flux calibrator compared to antenna 0, but a lower RMS. It has also found antennas 5 and 15 to be bad enough to flag out.</p>

<h5 id="13-view-ant_statstxt">13. View <code class="highlighter-rouge">ant_stats.txt</code></h5>

<p>You should see the following contents, corresponding to the amplitude and RMS each of the antennas measure</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ant median rms
0   8.84   305.28
1   7.80   251.12
2   7.69   279.64
3   8.13   219.86
4   9.37   322.45
5   7.10   253.62
6   7.95   254.35
7   8.10   199.94
8   8.21   326.82
9   10.15   306.20
10  9.00   258.92
11  11.57   270.17
12  10.55   270.40
13  13.38   396.25
14  13.66   434.22
15  243.71   569.51
</code></pre></div></div>

<h5 id="14-view-configtmp">14. View <code class="highlighter-rouge">.config.tmp</code></h5>

<p>You should now see <code class="highlighter-rouge">refant = 7</code> and <code class="highlighter-rouge">badants = [5, 15]</code>.</p>

<h5 id="15-edit-your-config-file-to-run-the-next-steps">15. Edit your config file to run the next steps</h5>

<p>Edit <code class="highlighter-rouge">tutorial_config.txt</code> to remove the first two and last six tuples in the <code class="highlighter-rouge">scripts</code> parameter, so it looks like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scripts = [('flag_round_1.py', True, ''), ('setjy.py', True, ''), ('xx_yy_solve.py', False, ''), ('xx_yy_apply.py', True, '')]
</code></pre></div></div>

<p>Replace <code class="highlighter-rouge">refant</code> and <code class="highlighter-rouge">badants</code> with what was found by <code class="highlighter-rouge">validate_input.py</code>, and select the submit option, so it looks like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[crosscal]
refant = 7
badants = [5, 15]
</code></pre></div></div>

<h5 id="16-run-the-pipeline-using-your-config-file">16. Run the pipeline using your config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>You should see the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 03:18:26,585 DEBUG: Copying 'tutorial_config.txt' to '.config.tmp', and using this to run pipeline.
2019-02-28 03:18:26,605 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again
2019-02-28 03:18:26,615 DEBUG: Wrote sbatch file "flag_round_1.sbatch"
2019-02-28 03:18:26,624 DEBUG: Wrote sbatch file "setjy.sbatch"
2019-02-28 03:18:26,631 DEBUG: Wrote sbatch file "xx_yy_solve.sbatch"
2019-02-28 03:18:26,639 DEBUG: Wrote sbatch file "xx_yy_apply.sbatch"
2019-02-28 03:18:26,647 INFO: Running master script "submit_pipeline.sh"
Copying tutorial_config.txt to .config.tmp, and using this to run pipeline.
Submitting flag_round_1.sbatch SLURM queue with following command:
sbatch flag_round_1.sbatch
Submitting setjy.sbatch SLURM queue with following command
sbatch -d afterok:1097919 --kill-on-invalid-dep=yes setjy.sbatch
Submitting xx_yy_solve.sbatch SLURM queue with following command
sbatch -d afterok:1097919,1097920 --kill-on-invalid-dep=yes xx_yy_solve.sbatch
Submitting xx_yy_apply.sbatch SLURM queue with following command
sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch
Submitted sbatch jobs with following IDs: 1097919,1097920,1097921,1097922
Run killJobs.sh to kill all the jobs.
Run summary.sh to view the progress.
Run findErrors.sh to find errors (after pipeline has run).
Run displayTimes.sh to display start and end timestamps (after pipeline has run).
</code></pre></div></div>

<p>As before, we see the sbatch files being written to our working directory. Since we set <code class="highlighter-rouge">submit=True</code>, <code class="highlighter-rouge">submit_pipeline.sh</code> has been run, and all output after that (without the timestamps) comes from this bash script. After the first job is run (<code class="highlighter-rouge">sbatch flag_round_1.sbatch</code>), each other job is run with a dependency on all previous jobs (e.g. <code class="highlighter-rouge">sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch</code>). We can see this by calling <code class="highlighter-rouge">squeue -u your_username</code>, which shows those jobs <code class="highlighter-rouge">(Dependency)</code>. <code class="highlighter-rouge">submit_pipeline.sh</code> then writes four job scripts, all of which are explained in the output, written to <code class="highlighter-rouge">jobScripts</code> with a timestamp appended to the filename, and symlinked from your working directory. <code class="highlighter-rouge">findErrors.sh</code> finds errors after this pipeline run has completed, overlooking all nominal MPI errors.</p>

<p>These tasks follow the first step of a two-step calibration process that is summarised in [[Calibration-in-processMeerKAT]].</p>

<h5 id="17-run-summarysh">17. Run <code class="highlighter-rouge">./summary.sh</code></h5>

<p>This script simply calls <code class="highlighter-rouge">sacct</code> for all jobs submitted within this pipeline run. You should get output similar to the following.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097927         flag_round_1          Main   00:00:04      2            8                                slwrk-[060-061]   00:00:00    RUNNING      0:0
1097927.0       orted                        00:00:04      1      1     1                                      slwrk-061   00:00:00    RUNNING      0:0
1097928         setjy                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097929         xx_yy_solve           Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
1097930         xx_yy_apply           Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
</code></pre></div></div>

<p>Those <code class="highlighter-rouge">PENDING</code> are the jobs with dependencies. Once this pipeline run has completed, <code class="highlighter-rouge">./summary.sh</code> should give output similar to the following.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097927         flag_round_1          Main   00:08:25      2            8                                slwrk-[060-061]  11:04.530  COMPLETED      0:0
1097927.batch   batch                        00:08:25      1      1     4       11759M        2971M            slwrk-060  04:46.830  COMPLETED      0:0
1097927.0       orted                        00:08:25      1      1     1       14493M        1084M            slwrk-061  06:17.699  COMPLETED      0:0
1097928         setjy                 Main   00:06:18      2            8                                slwrk-[060-061]  03:21.451  COMPLETED      0:0
1097928.batch   batch                        00:06:18      1      1     4       24722M       24575M            slwrk-060  02:23.206  COMPLETED      0:0
1097928.0       orted                        00:06:17      1      1     1        5779M        5655M            slwrk-061  00:58.245  COMPLETED      0:0
1097929         xx_yy_solve           Main   00:03:28      1            1                                      slwrk-066  01:59.767  COMPLETED      0:0
1097929.batch   batch                        00:03:28      1      1     1        0.22M        0.18M            slwrk-066  00:00.068  COMPLETED      0:0
1097929.0       singularity                  00:03:28      1      1     1       10275M           5M            slwrk-066  01:59.699  COMPLETED      0:0
1097930         xx_yy_apply           Main   00:06:30      2            8                                slwrk-[060-061]  03:32.520  COMPLETED      0:0
1097930.batch   batch                        00:06:30      1      1     4        8237M        4228M            slwrk-060  01:29.291  COMPLETED      0:0
1097930.0       orted                        00:06:29      1      1     1       13386M        6554M            slwrk-061  02:03.228  COMPLETED      0:0
</code></pre></div></div>

<h5 id="18-view-caltables-directory">18. View <code class="highlighter-rouge">caltables</code> directory</h5>

<p>The calibration solution tables have been written to <code class="highlighter-rouge">caltables/1491550051.*</code>, including <code class="highlighter-rouge">bcal, gcal, fluxscale</code> and <code class="highlighter-rouge">kcal</code>, corresponding to the calibration solutions for bandpass, complex gains, flux-scaled complex gains, and delays, respectively.</p>

<h5 id="19-run-displaytimessh">19. Run <code class="highlighter-rouge">./displayTimes.sh</code></h5>

<p>You should see output similar to the following, which shows this run took 24 minutes to complete, the longest of which was flagging for 8.5 minutes.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logs/flag_round_1-1097927.casa
2019-02-28 01:32:37
2019-02-28 01:40:32
logs/setjy-1097928.casa
2019-02-28 01:41:02
2019-02-28 01:46:49
logs/xx_yy_solve-1097929.casa
2019-02-28 01:47:15
2019-02-28 01:50:22
logs/xx_yy_apply-1097930.casa
2019-02-28 01:50:47
2019-02-28 01:56:49
</code></pre></div></div>

<h5 id="20-run-finderrorssh">20. Run <code class="highlighter-rouge">./findErrors.sh</code></h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logs/flag_round_1-1097927.out
logs/setjy-1097928.out
logs/xx_yy_solve-1097929.out
logs/xx_yy_apply-1097930.out
*** Error *** Error in data selection specification: MSSelectionNullSelection : The selected table has zero rows.
(The same error repeated another 23 times)
</code></pre></div></div>

<p>This error likely corresponds to empty sub-MS(s) with data completely flagged out, which give a worker node nothing to do for whichever CASA tasks are being called.</p>

<h5 id="21-rebuild-your-config-file-without-verbose-mode">21. Rebuild your config file without verbose mode</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -B -C tutorial_config.txt -M 1491550051.mms</code></p>

<table>
  <tbody>
    <tr>
      <td>This way we reset the list of scripts in our config file, and set <code class="highlighter-rouge">verbose=False</code> and <code class="highlighter-rouge">submit=False</code>. We will manually remove the scripts we already ran in step [[23</td>
      <td>#Run-the-pipeline-using-your-updated-config-file]], so leave the <code class="highlighter-rouge">scripts</code> parameter as is.</td>
    </tr>
  </tbody>
</table>

<h5 id="22-edit-your-config-file">22. Edit your config file</h5>

<p>Edit <code class="highlighter-rouge">tutorial_config.txt</code> to update the reference antenna to what <code class="highlighter-rouge">calc_refant.py</code> found as the best reference antenna. If you’ve forgotten that was, view it in <code class="highlighter-rouge">jobScripts/tutorial_config_*.txt</code> (antenna 7). We don’t need to update <code class="highlighter-rouge">badants</code> as only <code class="highlighter-rouge">flag_round_1.py</code> uses this parameter, which we will not be running.</p>

<h5 id="23-run-the-pipeline-using-your-updated-config-file">23. Run the pipeline using your updated config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>Since we have set <code class="highlighter-rouge">verbose=False</code> and <code class="highlighter-rouge">submit=False</code>, the pipeline will not yet run, and you should see simplified output like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 11:47:20,011 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again
2019-01-16 20:30:00,180 INFO: Master script "submit_pipeline.sh" written, but will not run.
</code></pre></div></div>

<h5 id="24-edit-submit_pipelinesh">24. Edit <code class="highlighter-rouge">submit_pipeline.sh</code></h5>

<p>You will see in <code class="highlighter-rouge">submit_pipeline.sh</code> that each sbatch job is submitted on its own line, and that the job ID is extracted. Remove everything from <code class="highlighter-rouge">#validate_input.sbatch</code> to one line before <code class="highlighter-rouge">#flag_round_2.sbatch</code>, so it looks like the following</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cp </span>tutorial_config.txt .config.tmp

<span class="c">#flag_round_2.sbatch</span>
<span class="nv">IDs</span><span class="o">=</span><span class="k">$(</span>sbatch flag_round_2.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#setjy.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>setjy.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#xy_yx_solve.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>xy_yx_solve.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#xy_yx_apply.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>xy_yx_apply.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#split.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>split.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#quick_tclean.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>quick_tclean.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#plot_solutions.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>plot_solutions.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#Output message and create jobScripts directory</span>
<span class="nb">echo </span>Submitted sbatch <span class="nb">jobs </span>with following IDs: <span class="nv">$IDs</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> jobScripts
	<span class="nb">.</span>
	<span class="nb">.</span>
	<span class="nb">.</span>
</code></pre></div></div>

<p><strong>Note the first line has been edited to replace <code class="highlighter-rouge">+=,</code> with <code class="highlighter-rouge">=</code> and remove <code class="highlighter-rouge">-d afterok:$IDs --kill-on-invalid-dep=yes</code>, since it does not have any dependencies.</strong></p>

<h5 id="25-run-submit_pipelinesh">25. Run <code class="highlighter-rouge">./submit_pipeline.sh</code></h5>

<p>Again, we see simplified output</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Submitted sbatch jobs with following IDs: 1097948,1097949,1097950,1097951,1097952,1097953,1097954
Run killJobs.sh to kill all the jobs.
Run summary.sh to view the progress.
Run findErrors.sh to find errors (after pipeline has run).
Run displayTimes.sh to display start and end timestamps (after pipeline has run).
</code></pre></div></div>

<p>These job IDs comprise the new pipeline run we’ve just launched. So now <code class="highlighter-rouge">./summary.sh</code> will display <code class="highlighter-rouge">sacct</code> for the new job IDs, similar to the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097948         flag_round_2          Main   00:01:49      2            8                                slwrk-[013,020]   00:00:00    RUNNING      0:0
1097948.0       orted                        00:01:45      1      1     1                                      slwrk-020   00:00:00    RUNNING      0:0
1097949         setjy                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097950         xy_yx_solve           Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
1097951         xy_yx_apply           Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097952         split                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097953         quick_tclean          Main   00:00:00      2           64                                  None assigned   00:00:00    PENDING      0:0
1097954         plot_solutions        Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
</code></pre></div></div>

<p>The 4 new ancillary (bash) jobScripts will also correspond to these 7 new job IDs. After this pipeline run has completed, viewing the output of <code class="highlighter-rouge">./displayTimes.sh</code> shows this run took XX minutes.</p>

<p>If you want to see the output from the job scripts referring to the old pipeline runs, don’t worry, they’re still in the <code class="highlighter-rouge">jobScripts</code> directory with an older timestamp in the filename. Only the symlink in your working directory has been updated.</p>

<table>
  <tbody>
    <tr>
      <td>These new tasks follow the second step of a two step calibration process that is summarised on [[this page</td>
      <td>Calibration-in-processMeerKAT]].</td>
    </tr>
  </tbody>
</table>

<p>After <code class="highlighter-rouge">split.py</code> has run, you will see three new files</p>

<p><code class="highlighter-rouge">1491550051.0252-712.mms 1491550051.0408-65.mms 1491550051.DEEP_2_off.mms</code></p>

<p>This corresponds to the data split out from <code class="highlighter-rouge">1491550051.mms</code>, for the bandpass/flux calibrator (<code class="highlighter-rouge">0408-65</code>), the phase calibrator (<code class="highlighter-rouge">0252-712</code>), and the science target (<code class="highlighter-rouge">DEEP_2_off</code>).</p>

<h5 id="26-view-the-images-in-the-images-directory">26. View the images in the <code class="highlighter-rouge">images</code> directory</h5>

<p><code class="highlighter-rouge">quick_tclean.py</code> creates quicklook images (i.e. with no selfcal, w-projection, threadholding, no-multiscale, etc) with robust weighting 0, for all fields specified in the config file, creating 512x512 images of the calibrator fields, and 2048x2048 images of the target field(s), both with 2 arcsec pixel sizes. For data with &gt; 100 MHz bandwidth, two taylor terms are used, otherwise the ‘clark’ deconvolver is used.</p>

<h5 id="27-view-the-figures-in-plots-directory">27. View the figures in <code class="highlighter-rouge">plots</code> directory</h5>

<p>The last script that runs is <code class="highlighter-rouge">plot_solutions.py</code>, which calls CASA task <code class="highlighter-rouge">plotms</code> to plot the calibration solutions for the bandpass calibrator and the phase calibrator. This is the reason that <code class="highlighter-rouge">xvfb-run</code> is called, which runs a virtual X server to make use of the plotting libraries. Your plots should look like the following.</p>

<p><img src="/assets/bpass_chan_amp.png" alt="bpass_chan_amp" />
<img src="/assets/bpass_chan_phase.png" alt="bpass_chan_phase" />
<img src="/assets/bpass_real_imag.png" alt="bpass_real_imag" />
<img src="/assets/phasecal_time_amp.png" alt="phasecal_time_amp" />
<img src="/assets/phasecal_time_phase.png" alt="phasecal_time_phase" /></p>

<p><strong>That’s it! You have completed the tutorial! Now go forth and do some phenomenal MeerKAT science!</strong></p>

<h3 id="also-see">Also see</h3>

<ul>
  <li><a href="../Calibration-in-processMeerKAT">Calibration in processMeerKAT</a></li>
  <li><a href="../Diagnosing-Errors">Diagnosing Errors</a></li>
  <li><a href="../Using-the-pipeline">Using the pipeline</a></li>
</ul>



          
        </div>
      </div>
    </div>
  </div>

</body>
</html>
