<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">
  

  <title>DEEP 2 Tutorial - IDIA Pipelines</title>
  <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css">
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>

  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000/" class="site-title fs-6 lh-tight">IDIA Pipelines</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav role="navigation" aria-label="Main navigation">
  <ul class="navigation-list">
    
    
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/" class="navigation-list-link">Home</a>
            
          </li>
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/access/" class="navigation-list-link">Access to IDIA Machines</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/docs/processMeerKAT" class="navigation-list-link">processMeerKAT</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Quick-Start/" class="navigation-list-link">Quick Start</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Release-Notes/" class="navigation-list-link">Release Notes</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/using-the-pipeline/" class="navigation-list-link">Using the Pipeline</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Example-Use-Cases/" class="navigation-list-link">Example Use Cases</a>
                      
                    </li>
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/Diagnosing-Errors/" class="navigation-list-link">Diagnosing Errors</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item  active">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/deep-2-tutorial/" class="navigation-list-link active">DEEP 2 Tutorial</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/calibration-in-processmeerkat/" class="navigation-list-link">Calibration in processMeerKAT</a>
                      
                    </li>
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/docs/processMeerKAT/SLURM-and-MPICASA/" class="navigation-list-link">SLURM and MPICASA</a>
                      
                    </li>
                  
                
              </ul>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/docs/containers/" class="navigation-list-link">Singularity Containers</a>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" tabindex="0" placeholder="Search IDIA Pipelines" aria-label="Search IDIA Pipelines" autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="//github.com/idia-astro/pipelines/wiki">IDIA Pipelines</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content js-main-content" tabindex="0">
        
          
            <nav class="breadcrumb-nav">
              <ol class="breadcrumb-nav-list">
                
                  <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/processMeerKAT">processMeerKAT</a></li>
                
                <li class="breadcrumb-nav-list-item"><span>DEEP 2 Tutorial</span></li>
              </ol>
            </nav>
          
        
        <div id="main-content" class="page-content" role="main">
          <h1 id="deep-2-tutorial">DEEP 2 Tutorial</h1>

<h3 id="this-tutorial-walks-you-through-running-the-various-steps-of-the-pipeline-for-a-single-deep-2-dataset-which-is-a-snapshot-20-minutes-on-source-16-dish-meerkat-observation-of-a-random-patch-of-sky-using-the-old-roach-2-correlator-11-gb-in-size">This tutorial walks you through running the various steps of the pipeline for a single DEEP 2 dataset, which is a snapshot (~20 minutes on source), 16-dish MeerKAT observation of a random patch of sky using the old ROACH-2 correlator, 11 GB in size.</h3>

<p>To begin, ssh into the ilifu cluster (<code class="highlighter-rouge">slurm.ilifu.ac.za</code>), and create a working directory somewhere on the filesystem (e.g. <code class="highlighter-rouge">/scratch/users/your_username/tutorial/</code>).</p>

<h5 id="1-source-setupsh-which-will-add-to-your-path-and-pythonpath">1. Source <code class="highlighter-rouge">setup.sh</code>, which will add to your PATH and PYTHONPATH</h5>

<p><code class="highlighter-rouge">source /idia/software/pipelines/master/setup.sh</code></p>

<h5 id="2-build-a-config-file-using-verbose-mode-and-pointing-to-the-deep-2-dataset">2. Build a config file, using verbose mode, and pointing to the DEEP 2 dataset</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -B -C tutorial_config.txt -M /idia/projects/deep/1491550051.ms -v</code></p>

<p>You should get the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2020-05-12 14:51:34,877 INFO: Extracting field IDs from measurement set "/idia/projects/deep/1491550051.ms" using CASA.
2020-05-12 14:51:34,877 DEBUG: Using the following command:
	srun --qos qos-interactive --nodes=1 --ntasks=1 --time=10 --mem=4GB --partition=Main singularity run /idia/software/containers/casa-stable-5.6.2-2.simg  /users/jcollier/Scripts/pipelines/processMeerKAT/cal_scripts/get_fields.py -B -M /idia/projects/deep/1491550051.ms -C tutorial_config.txt -N 8 -t 4 2&gt;&amp;1 | grep -v 'msmetadata_cmpt.cc::open\|MSMetaData::_computeScanAndSubScanProperties'
2020-05-12 14:51:36,883 INFO: Using reference antenna 'm059'.
2020-05-12 14:51:36,883 INFO: This is usually a well-behaved (stable) antenna. Update 'refant' in [crosscal] section of 'tutorial_config.txt' to change this.
2020-05-12 14:51:36,929 WARNING: The number of threads (8 node(s) x 4 task(s) = 32) is not ideal compared to the number of scans (12) for "/idia/projects/deep/1491550051.ms".
2020-05-12 14:51:36,929 WARNING: Config file has been updated to use 1 node(s) and 8 task(s) per node.
2020-05-12 14:51:36,929 INFO: For the best results, update your config file so that nodes x tasks per node = 7.
2020-05-12 14:51:37,154 INFO: Multiple fields found with intent "CALIBRATE_FLUX" in dataset "/idia/projects/deep/1491550051.ms" - [0 1].
2020-05-12 14:51:37,158 WARNING: Only using field "0" for "fluxfield", which has the most scans (1).
2020-05-12 14:51:37,158 WARNING: Putting extra fields with intent "CALIBRATE_FLUX" in "targetfields" - [1]
2020-05-12 14:51:37,158 INFO: Multiple fields found with intent "CALIBRATE_BANDPASS" in dataset "/idia/projects/deep/1491550051.ms" - [0 1].
2020-05-12 14:51:37,159 WARNING: Only using field "0" for "bpassfield", which has the most scans (1).
2020-05-12 14:51:37,159 INFO: Multiple fields found with intent "CALIBRATE_PHASE" in dataset "/idia/projects/deep/1491550051.ms" - [1 2].
2020-05-12 14:51:37,159 WARNING: Only using field "2" for "phasecalfield", which has the most scans (5).
2020-05-12 14:51:37,165 INFO: [fields] section written to "tutorial_config.txt". Edit this section if you need to change field IDs (comma-seperated string for multiple IDs).
2020-05-12 14:51:37,541 INFO: Config "tutorial_config.txt" generated.
</code></pre></div></div>

<p>This calls CASA via the default singularity container without writing log files, and runs <code class="highlighter-rouge">get_fields.py</code>. It calls <code class="highlighter-rouge">srun</code>, requesting only 1 node, 1 task, 4 GB of memory, and a 10 minute time limit, to increase the likelihood of launching <code class="highlighter-rouge">srun</code> immediately. The purpose of this call is to extract the field IDs corresponding to our different targets, and check the nodes and tasks per node against the number of scans, each of which is handled by a thread (see section 3). The output statements with <code class="highlighter-rouge">DEBUG</code> correspond to those output during verbose mode. The warnings display when multiple fields are present with the same intent, but only one is extracted, corresponding to the field with the most scans. In this case the extras are moved to <code class="highlighter-rouge">targetfields</code> (i.e. for applying calibration and imaging).</p>

<h5 id="3-view-the-config-file-created-which-has-the-following-contents">3. View the config file created, which has the following contents:</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[data]
vis = '/idia/projects/deep/1491550051.ms'

[fields]
bpassfield = '0'
fluxfield = '0'
phasecalfield = '2'
targetfields = '3,1'

[slurm]
nodes = 1
ntasks_per_node = 8
plane = 1
mem = 236
partition = 'Main'
exclude = ''
time = '12:00:00'
submit = False
container = '/idia/software/containers/casa-stable-5.6.2-2.simg'
mpi_wrapper = '/idia/software/pipelines/casa-pipeline-release-5.6.1-8.el7/bin/mpicasa'
name = ''
dependencies = ''
account = 'b03-idia-ag'
reservation = ''
verbose = True
precal_scripts = [('calc_refant.py', False, ''), ('partition.py', True, '')]
postcal_scripts = [('concat.py', False, '')]
scripts = [('validate_input.py', False, ''), ('flag_round_1.py', True, ''), ('calc_refant.py', False, ''), ('setjy.py', True, ''), ('xx_yy_solve.py', False, ''), ('xx_yy_apply.py', True, ''), ('flag_round_2.py', True, ''), ('xx_yy_solve.py', False, ''), ('xx_yy_apply.py', True, ''), ('split.py', True, ''), ('quick_tclean.py', True, ''), ('plot_solutions.py', False, '')]

[crosscal]
minbaselines = 4                  # Minimum number of baselines to use while calibrating
preavg = 1                        # Number of channels to average before calibration (during partition)
specavg = 1                       # Number of channels to average after calibration (during split)
timeavg = '8s'                    # Time interval to average after calibration (during split)
keepmms = True                    # Output MMS (True) or MS (False) during split
spw = '0:860~1680MHz'             # Spectral window / frequencies to extract for MMS
nspw = 16                         # Number of spectral windows to split into
calcrefant = True                 # Calculate reference antenna in program (overwrites 'refant')
refant = 'm059'                   # Reference antenna name / number
standard = 'Stevens-Reynolds 2016'# Flux density standard for setjy
badants = []                      # List of bad antenna numbers (to flag)
badfreqranges = [ '933~960MHz',   # List of bad frequency ranges (to flag)
        '1163~1299MHz',
        '1524~1630MHz']

[run]
continue = True
</code></pre></div></div>

<p>This config file contains five sections - data, fields, slurm, crosscal, and run. The fields IDs we just extracted, seen in section <code class="highlighter-rouge">[fields]</code>, correspond to field 0 for the bandpass calibrator, field 0 for the total flux calibrator, field 2 for the phase calibrator, and fields 3 and 1 for the science targets (i.e. the DEEP 2 field + another calibrator). Only the target may have multiple fields. If a field isn’t found according to its intent, a warning is displayed, and the field for the total flux calibrator is selected. If the total flux calibrator isn’t present, the program will display an error and terminate. The <code class="highlighter-rouge">[run]</code> section is used internally by the pipeline, and should be ignored.</p>

<p>The SLURM parameters in section <code class="highlighter-rouge">[slurm]</code> correspond to those seen by running <code class="highlighter-rouge">processMeerKAT.py -h</code>. The pipeline executes all the scripts from the <code class="highlighter-rouge">scripts</code> parameter in order, including any of your own that you can insert (see <a href="/docs/processMeerKAT/using-the-pipeline#inserting-your-own-scripts">Using the Pipeline</a>). The <code class="highlighter-rouge">precal_scripts</code> and <code class="highlighter-rouge">postcal_scripts</code> are only relevant when <code class="highlighter-rouge">nspw</code> &gt; 1 (the default is <code class="highlighter-rouge">nspw=16</code>), where as we will set <code class="highlighter-rouge">nspw=1</code> in this tutorial, meaning that in the next step, the scripts in <code class="highlighter-rouge">precal_scripts</code> will be prepended to the beginning of <code class="highlighter-rouge">scripts</code>, and the scripts in <code class="highlighter-rouge">postcal_scripts</code> will be appended to the end of <code class="highlighter-rouge">scripts</code>. See the <a href="link-TBD">MIGHTEE tutorial</a> when using <code class="highlighter-rouge">nspw</code> &gt; 1.</p>

<p>By default, for all threadsafe scripts (i.e. those with <code class="highlighter-rouge">True</code> in the <code class="highlighter-rouge">scripts</code> list), we use 2 nodes, 8 tasks per node (=16 threads), 236 GB of memory (per node), and <code class="highlighter-rouge">plane=1</code> (an argument that distributes N tasks onto one node before moving onto next node). During step 2, only 12 scans were found, and since <code class="highlighter-rouge">partition.py</code> partitions the data into one sub-measurement set (sub-MS) per scan, only 12 sub-MSs will exist in the multi-measurement set (MMS - see <a href="#10-view-the-contents-of-1491550051mms">section 10 below</a>). Assuming each observation has a phase calibrator bracketing each target scan, at most, 6 sub-MSs will be operated on at any given time, each handled by one thread, and a master thread. So we aim to have a limit of nscans+1+10% threads, with the 10% to account for the occasional thread that hangs. For this dataset, this limit is 7 threads, so <code class="highlighter-rouge">get_fields.py</code> attempts to match this number by using the specified number of tasks per node and increasing the node count from 1 until the number of threads is more than the limit, terminating at 1 nodes x 8 tasks per node = 8 threads.</p>

<p>For script that aren’t threadsafe (i.e. those with <code class="highlighter-rouge">False</code> in the <code class="highlighter-rouge">scripts</code> list), we use a single node, and a single task per node. For the majority scripts that are threadsafe and those that aren’t, we use a single CPU per task, and explicitly export <code class="highlighter-rouge">OMP_NUM_THREADS=1</code>, since there is little evidence of a speedup with more than one CPU per task. However, for <code class="highlighter-rouge">partition.py</code> we use between 2-4 CPUs per task (equal to the number of polarisations, which is 2 by default, but 4 if <code class="highlighter-rouge">[-D --dopol]</code> is used, which adds the <code class="highlighter-rouge">xy_yx_solve.py</code> or <code class="highlighter-rouge">xy_yx_apply.py</code> scripts to the <code class="highlighter-rouge">scripts</code> parameter in your config). Furthermore, <code class="highlighter-rouge">quick_tclean.py</code> will use as many CPUs as it can without exceeding 32 in total.</p>

<p>The cross-calibration parameters in section <code class="highlighter-rouge">[crosscal]</code> correspond to various CASA parameters passed into the calibration tasks that the pipeline used, each of which is documented <a href="/docs/processMeerKAT/calibration-in-processmeerkat">here</a>. By default all frequency ranges listed in <code class="highlighter-rouge">badfreqranges</code>, and all antenna numbers listed in <code class="highlighter-rouge">badants</code>, will be flagged out entirely. The third script the pipeline runs (<code class="highlighter-rouge">calc_refant.py</code>) will likely change the value of <code class="highlighter-rouge">refant</code>, and add a list of bad antennas to <code class="highlighter-rouge">badants</code>.</p>

<h5 id="4-edit-your-config-file-to-set-nspw1-and-then-run-the-pipeline-using-your-config-file">4. Edit your config file to set <code class="highlighter-rouge">nspw=1</code>, and then run the pipeline using your config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>You should get the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2020-05-12 15:08:42,808 WARNING: Appending "precal_scripts" to beginning of "scripts", and "postcal_script" to end of "scripts", since nspw=1. Overwritting this in "tutorial_config.txt".
2020-05-12 15:08:42,844 DEBUG: Copying 'tutorial_config.txt' to '.config.tmp', and using this to run pipeline.
2020-05-12 15:08:42,848 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again.
2020-05-12 15:08:42,854 DEBUG: Wrote sbatch file "calc_refant.sbatch"
2020-05-12 15:08:42,858 DEBUG: Wrote sbatch file "partition.sbatch"
2020-05-12 15:08:42,861 DEBUG: Wrote sbatch file "validate_input.sbatch"
2020-05-12 15:08:42,865 DEBUG: Wrote sbatch file "flag_round_1.sbatch"
2020-05-12 15:08:42,868 DEBUG: Wrote sbatch file "calc_refant.sbatch"
2020-05-12 15:08:42,871 DEBUG: Wrote sbatch file "setjy.sbatch"
2020-05-12 15:08:42,875 DEBUG: Wrote sbatch file "xx_yy_solve.sbatch"
2020-05-12 15:08:42,878 DEBUG: Wrote sbatch file "xx_yy_apply.sbatch"
2020-05-12 15:08:42,881 DEBUG: Wrote sbatch file "flag_round_2.sbatch"
2020-05-12 15:08:42,885 DEBUG: Wrote sbatch file "xx_yy_solve.sbatch"
2020-05-12 15:08:42,888 DEBUG: Wrote sbatch file "xx_yy_apply.sbatch"
2020-05-12 15:08:42,891 DEBUG: Wrote sbatch file "split.sbatch"
2020-05-12 15:08:42,894 DEBUG: Wrote sbatch file "quick_tclean.sbatch"
2020-05-12 15:08:42,898 DEBUG: Wrote sbatch file "plot_solutions.sbatch"
2020-05-12 15:08:42,902 DEBUG: Wrote sbatch file "concat.sbatch"
2020-05-12 15:08:42,904 INFO: Master script "submit_pipeline.sh" written, but will not run.```

A number of sbatch files have now been written to your working directory, each of which corresponds to the python script in the list of scripts set by the `scripts` parameter in our config file. Our config file was copied to `.config.tmp`, which is the config file written and edited by the pipeline, which the user should not touch. A bash script called `submit_pipeline.sh` was written, which we will look at soon. However, this script was not run, since we set `submit = False` in our config file (you can change this in your config file, or by using option `[-s --submit]` when you build your config file with `processMeerKAT.py`). Lastly, a `logs` directory was created, which will store the log files from the SLURM output.

##### 5. View `validate_input.sbatch`, which has the following contents:

</code></pre></div></div>
<p>#!/bin/bash
#SBATCH –account=b03-idia-ag
#SBATCH –nodes=1
#SBATCH –ntasks-per-node=1
#SBATCH –cpus-per-task=1
#SBATCH –mem=236GB
#SBATCH –job-name=validate_input
#SBATCH –distribution=plane=1
#SBATCH –output=logs/%x-%j.out
#SBATCH –error=logs/%x-%j.err
#SBATCH –partition=Main
#SBATCH –time=12:00:00</p>

<p>export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export OMPI_MCA_btl_tcp_if_exclude=’192.168.100.0/24’</p>

<p>srun singularity run /idia/software/containers/casa-stable-5.6.2-2.simg  casa –nologger –nogui –logfile logs/${SLURM_JOB_NAME}-${SLURM_JOB_ID}.casa -c /users/jcollier/Scripts/pipelines/processMeerKAT/cal_scripts/validate_input.py –config .config.tmp 2&gt;&amp;1 | grep -v ‘msmetadata_cmpt.cc::open|MSMetaData::_computeScanAndSubScanProperties’</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Since this script is not threadsafe, the job is called with `srun`, and is configured to run a single task on a single node. The last line shows the CASA call of the `validate_input.py` task, which will validate the parameters in the config file.

##### 6. Run the first sbatch job

```sbatch validate_input.sbatch```

You should see the following output, corresponding to your SLURM job ID

```Submitted batch job 1281331```

##### 7. View your job in the SLURM queue (if you weren't quick enough, repeat step 6, and quickly do step 7)

`squeue`

You will see something similar to the following, with other people's jobs mixed into the queue.

</code></pre></div></div>
<p>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
1281331      Main validate jcollier  R       0:13      1 slwrk-121</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We can see the job with name `validate` was submitted to SLURM worker node 121, amongst a number of jobs in the Main partition, the Jupyter Spawner partition, and possible other partitions. Your job may list `(Priority)`, which means it is too low a priority to be run at this point, or `(Resources)`, which means it is waiting for resources to be made available.

*NOTE: You can view just your jobs with `squeue -u your_username`, an individual job with `squeue -j 1281331`, and just the jobs in the main partition with `squeue -p Main`. You can view which nodes are allocated, which are idle, which are mixed (i.e. partially allocated), and which are down in the main partition with `sinfo -p Main`. Often it is good idea to check this before selecting your SLURM parameters. More more information: see [docs](URL-here)*


##### 8. View `partition.sbatch`, which has the following contents:

</code></pre></div></div>
<p>#!/bin/bash
#SBATCH –account=b03-idia-ag
#SBATCH –nodes=1
#SBATCH –ntasks-per-node=8
#SBATCH –cpus-per-task=2
#SBATCH –mem=236GB
#SBATCH –job-name=partition
#SBATCH –distribution=plane=1
#SBATCH –output=logs/%x-%j.out
#SBATCH –error=logs/%x-%j.err
#SBATCH –partition=Main
#SBATCH –time=12:00:00</p>

<p>export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export OMPI_MCA_btl_tcp_if_exclude=’192.168.100.0/24’</p>

<p>/idia/software/pipelines/casa-pipeline-release-5.6.1-8.el7/bin/mpicasa singularity exec /idia/software/containers/casa-stable-5.6.2-2.simg  casa –nologger –nogui –logfile logs/${SLURM_JOB_NAME}-${SLURM_JOB_ID}.casa -c /users/jcollier/Scripts/pipelines/processMeerKAT/cal_scripts/partition.py –config .config.tmp</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Here we see the same default SLURM parameters for threadsafe tasks, as discussed in [section 3](#3-view-the-config-file-created-which-has-the-following-contents). We now use mpicasa as the mpi wrapper, since we are calling a threadsafe script `partition.py`, which calls CASA task `partition`, which partitions the data into several sub measurement sets (sub-MSs - see [section 10 below](#10-view-the-contents-of-1491550051mms)) and selects only frequencies specified by your spectral window with parameter `spw` in your config file.

##### 9. Submit your job and watch it in the queue

</code></pre></div></div>
<p>sbatch partition.sbatch
Submitted batch job 1097917
squeue -j 1097917</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
You will see something similar to the following, showing that 2 nodes are now being used (worker nodes 60 &amp; 61).

</code></pre></div></div>
<p>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
1097917      Main partitio jcollier  R       0:22      2 slwrk-[060-061]</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Wait until the job completes, before step 10.

##### 10. View the contents of `1491550051.mms`.

You should see two new files - `1491550051.mms` and `1491550051.mms.flagversions`, which corresponds to the data and flag data of a multi-measurement set (MMS). From now on, the pipeline operates on these data, rather than the . The same path to the original MS will remain in your config file under section `[data]`, but each task will point to your MMS.

Inside this MMS, you will find the same tables and metadata as in a normal MS, but you will also see a `SUBMSS` directory, which should have the following contents.

</code></pre></div></div>
<p>1491550051.mms.0000.ms  1491550051.mms.0004.ms  1491550051.mms.0008.ms
1491550051.mms.0001.ms  1491550051.mms.0005.ms  1491550051.mms.0009.ms
1491550051.mms.0002.ms  1491550051.mms.0006.ms  1491550051.mms.0010.ms
1491550051.mms.0003.ms  1491550051.mms.0007.ms  1491550051.mms.0011.ms</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
These are the 12 sub-MSs, partitioned by this observation's 12 scans of the various targets.

If we now view the CASA log, you will find a bunch of junk output from mpicasa (often including nominal "errors", sometimes severe), and 13 calls of `partition`, corresponding to 12 workers for your 12 sub-MSs, and one master process. Similarly, your standard output logs will contains 8 sets of output from CASA launching, corresponding to the 8 threads (i.e. 2 nodes x 4 tasks per node) and some junk output from mpicasa. Again, your standard error log should be empty.


##### 11. Run `calc_refant.sbatch` and watch your submitted job

</code></pre></div></div>
<p>sbatch calc_refant.sbatch
watch sacct</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
You will initially see something similar to the following

</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   JobID    JobName  Partition    Account  AllocCPUS      State ExitCode ------------ ---------- ---------- ---------- ---------- ---------- -------- 1097917       partition       Main b03-pipel+          8  COMPLETED      0:0 1097917.bat+      batch            b03-pipel+          4  COMPLETED      0:0 1097917.0         orted            b03-pipel+          1  COMPLETED      0:0 1097918      calc_refa+       Main b03-pipel+          1    RUNNING      0:0 1097918.0    singulari+            b03-pipel+          1    RUNNING      0:0 ```
</code></pre></div></div>

<p><code class="highlighter-rouge">sacct</code> lists all recently submitted jobs and their status. If your job fails, it will list <code class="highlighter-rouge">FAILED</code> under <code class="highlighter-rouge">State</code>. However, please note jobs running <code class="highlighter-rouge">mpicasa</code> often state they have failed when they haven’t. Similarly, when jobs do genuinely fail, the pipeline may continue to run. Both of these are issues we are working to overcome.</p>

<p>When your job completes, you will see something similar to the following</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       JobID    JobName  Partition    Account  AllocCPUS      State ExitCode
------------ ---------- ---------- ---------- ---------- ---------- --------
1097917       partition       Main b03-pipel+          8  COMPLETED      0:0
1097917.bat+      batch            b03-pipel+          4  COMPLETED      0:0
1097917.0         orted            b03-pipel+          1  COMPLETED      0:0
1097918      calc_refa+       Main b03-pipel+          1  COMPLETED      0:0
1097918.bat+      batch            b03-pipel+          1  COMPLETED      0:0
1097918.0    singulari+            b03-pipel+          1  COMPLETED      0:0
</code></pre></div></div>

<p>Control-C to exit out of <code class="highlighter-rouge">watch</code>.</p>

<h5 id="12-view-the-contents-of-your-logs-directory">12. View the contents of your <code class="highlighter-rouge">logs</code> directory</h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ls logs
calc_refant-1097918.casa  calc_refant-1097918.err  calc_refant-1097918.out
partition-1097917.casa  partition-1097917.err  partition-1097917.out
validate_input-1097914.casa  validate_input-1097914.err  validate_input-1097914.out
</code></pre></div></div>

<p>As specified in our sbatch file, standard out is written to <code class="highlighter-rouge">logs/calc_refant-1097918.out</code>, standard error is written to <code class="highlighter-rouge">logs/calc_refant-1097918.err</code>, and the CASA logs are written to <code class="highlighter-rouge">logs/calc_refant-1097918.casa</code>. Your standard output log and CASA log will have little of interest, but your standard error log will contain the following output:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 03:02:33,870 INFO: Flux field scan no: 1
2019-02-28 03:02:34,034 INFO: Antenna statistics on total flux calibrator
2019-02-28 03:02:34,035 INFO: (flux in Jy averaged over scans &amp; channels, and over all of each antenna's baselines)
2019-02-28 03:02:34,035 INFO: ant median rms
2019-02-28 03:03:10,900 INFO: All 8.92  275.02
2019-02-28 03:03:10,900 INFO: 7   8.10  199.94 (best antenna)
2019-02-28 03:03:10,900 INFO: 0   8.84  305.28 (1st good antenna)
2019-02-28 03:03:10,900 INFO: setting reference antenna to: 7
2019-02-28 03:03:10,900 INFO: Bad antennas: [5, 15]
</code></pre></div></div>

<p>Here we see <code class="highlighter-rouge">calc_refant.py</code> has selected antenna 7 as the best reference antenna, which measures comparable amplitude for the total flux calibrator compared to antenna 0, but a lower RMS. It has also found antennas 5 and 15 to be bad enough to flag out.</p>

<h5 id="13-view-ant_statstxt-and-configtmp">13. View <code class="highlighter-rouge">ant_stats.txt</code> and <code class="highlighter-rouge">.config.tmp</code></h5>

<p>You should see the following contents in <code class="highlighter-rouge">ant_stats.txt</code>, corresponding to the amplitude and RMS each of the antennas measure</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ant median rms
0   8.84   305.28
1   7.80   251.12
2   7.69   279.64
3   8.13   219.86
4   9.37   322.45
5   7.10   253.62
6   7.95   254.35
7   8.10   199.94
8   8.21   326.82
9   10.15   306.20
10  9.00   258.92
11  11.57   270.17
12  10.55   270.40
13  13.38   396.25
14  13.66   434.22
15  243.71   569.51
</code></pre></div></div>

<p>You should now see <code class="highlighter-rouge">refant = 7</code> and <code class="highlighter-rouge">badants = [5, 15]</code> in <code class="highlighter-rouge">.config.tmp</code>.</p>

<h5 id="14-edit-your-config-file-to-run-the-next-steps">14. Edit your config file to run the next steps</h5>

<p>Edit <code class="highlighter-rouge">tutorial_config.txt</code> to remove the first three and last seven tuples in the <code class="highlighter-rouge">scripts</code> parameter, so it looks like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scripts = [('flag_round_1.py', True, ''), ('setjy.py', True, ''), ('xx_yy_solve.py', False, ''), ('xx_yy_apply.py', True, '')]
</code></pre></div></div>

<p>Replace <code class="highlighter-rouge">refant</code> and <code class="highlighter-rouge">badants</code> with what was found by <code class="highlighter-rouge">validate_input.py</code>, select the submit option, and update <code class="highlighter-rouge">vis</code> to the MMS, so it looks like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[crosscal]
refant = 7
badants = [5, 15]
  .
  .
[slurm]
submit = True
  .
  .
[data]
vis = 1491550051.mms
</code></pre></div></div>

<h5 id="15-run-the-pipeline-using-your-config-file">15. Run the pipeline using your config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>You should see the following output, with different timestamps</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 03:18:26,585 DEBUG: Copying 'tutorial_config.txt' to '.config.tmp', and using this to run pipeline.
2019-02-28 03:18:26,605 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again
2019-02-28 03:18:26,615 DEBUG: Wrote sbatch file "flag_round_1.sbatch"
2019-02-28 03:18:26,624 DEBUG: Wrote sbatch file "setjy.sbatch"
2019-02-28 03:18:26,631 DEBUG: Wrote sbatch file "xx_yy_solve.sbatch"
2019-02-28 03:18:26,639 DEBUG: Wrote sbatch file "xx_yy_apply.sbatch"
2019-02-28 03:18:26,647 INFO: Running master script "submit_pipeline.sh"
Copying tutorial_config.txt to .config.tmp, and using this to run pipeline.
Submitting flag_round_1.sbatch SLURM queue with following command:
sbatch flag_round_1.sbatch
Submitting setjy.sbatch SLURM queue with following command
sbatch -d afterok:1097919 --kill-on-invalid-dep=yes setjy.sbatch
Submitting xx_yy_solve.sbatch SLURM queue with following command
sbatch -d afterok:1097919,1097920 --kill-on-invalid-dep=yes xx_yy_solve.sbatch
Submitting xx_yy_apply.sbatch SLURM queue with following command
sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch
Submitted sbatch jobs with following IDs: 1097919,1097920,1097921,1097922
Run killJobs.sh to kill all the jobs.
Run summary.sh to view the progress.
Run findErrors.sh to find errors (after pipeline has run).
Run displayTimes.sh to display start and end timestamps (after pipeline has run).
</code></pre></div></div>

<p>As before, we see the sbatch files being written to our working directory. Since we set <code class="highlighter-rouge">submit=True</code>, <code class="highlighter-rouge">submit_pipeline.sh</code> has been run, and all output after that (without the timestamps) comes from this bash script. After the first job is run (<code class="highlighter-rouge">sbatch flag_round_1.sbatch</code>), each other job is run with a dependency on all previous jobs (e.g. <code class="highlighter-rouge">sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch</code>). We can see this by calling <code class="highlighter-rouge">squeue -u your_username</code>, which shows those jobs <code class="highlighter-rouge">(Dependency)</code>. <code class="highlighter-rouge">submit_pipeline.sh</code> then writes four job scripts, all of which are explained in the output, written to <code class="highlighter-rouge">jobScripts</code> with a timestamp appended to the filename, and symlinked from your working directory. <code class="highlighter-rouge">findErrors.sh</code> finds errors after this pipeline run has completed, overlooking all nominal MPI errors.</p>

<p>These tasks follow the first step of a two-step calibration process that is summarised <a href="/docs/processMeerKAT/calibration-in-processmeerkat">here</a>.</p>

<h5 id="16-run-summarysh">16. Run <code class="highlighter-rouge">./summary.sh</code></h5>

<p>This script simply calls <code class="highlighter-rouge">sacct</code> for all jobs submitted within this pipeline run. You should get output similar to the following.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097927         flag_round_1          Main   00:00:04      2            8                                slwrk-[060-061]   00:00:00    RUNNING      0:0
1097927.0       orted                        00:00:04      1      1     1                                      slwrk-061   00:00:00    RUNNING      0:0
1097928         setjy                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097929         xx_yy_solve           Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
1097930         xx_yy_apply           Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
</code></pre></div></div>

<p>Those <code class="highlighter-rouge">PENDING</code> are the jobs with dependencies. Once this pipeline run has completed, <code class="highlighter-rouge">./summary.sh</code> should give output similar to the following.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097927         flag_round_1          Main   00:08:25      2            8                                slwrk-[060-061]  11:04.530  COMPLETED      0:0
1097927.batch   batch                        00:08:25      1      1     4       11759M        2971M            slwrk-060  04:46.830  COMPLETED      0:0
1097927.0       orted                        00:08:25      1      1     1       14493M        1084M            slwrk-061  06:17.699  COMPLETED      0:0
1097928         setjy                 Main   00:06:18      2            8                                slwrk-[060-061]  03:21.451  COMPLETED      0:0
1097928.batch   batch                        00:06:18      1      1     4       24722M       24575M            slwrk-060  02:23.206  COMPLETED      0:0
1097928.0       orted                        00:06:17      1      1     1        5779M        5655M            slwrk-061  00:58.245  COMPLETED      0:0
1097929         xx_yy_solve           Main   00:03:28      1            1                                      slwrk-066  01:59.767  COMPLETED      0:0
1097929.batch   batch                        00:03:28      1      1     1        0.22M        0.18M            slwrk-066  00:00.068  COMPLETED      0:0
1097929.0       singularity                  00:03:28      1      1     1       10275M           5M            slwrk-066  01:59.699  COMPLETED      0:0
1097930         xx_yy_apply           Main   00:06:30      2            8                                slwrk-[060-061]  03:32.520  COMPLETED      0:0
1097930.batch   batch                        00:06:30      1      1     4        8237M        4228M            slwrk-060  01:29.291  COMPLETED      0:0
1097930.0       orted                        00:06:29      1      1     1       13386M        6554M            slwrk-061  02:03.228  COMPLETED      0:0
</code></pre></div></div>

<h5 id="17-view-caltables-directory">17. View <code class="highlighter-rouge">caltables</code> directory</h5>

<p>The calibration solution tables have been written to <code class="highlighter-rouge">caltables/1491550051.*</code>, including <code class="highlighter-rouge">bcal, gcal, fluxscale</code> and <code class="highlighter-rouge">kcal</code>, corresponding to the calibration solutions for bandpass, complex gains, flux-scaled complex gains, and delays, respectively.</p>

<h5 id="18-run-displaytimessh">18. Run <code class="highlighter-rouge">./displayTimes.sh</code></h5>

<p>You should see output similar to the following, which shows this run took ~24 minutes to complete, the longest of which was flagging for ~8 minutes.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logs/flag_round_1-1097927.casa
2019-02-28 01:32:37
2019-02-28 01:40:32
logs/setjy-1097928.casa
2019-02-28 01:41:02
2019-02-28 01:46:49
logs/xx_yy_solve-1097929.casa
2019-02-28 01:47:15
2019-02-28 01:50:22
logs/xx_yy_apply-1097930.casa
2019-02-28 01:50:47
2019-02-28 01:56:49
</code></pre></div></div>

<h5 id="19-run-finderrorssh">19. Run <code class="highlighter-rouge">./findErrors.sh</code></h5>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>logs/flag_round_1-1097927.out
logs/setjy-1097928.out
logs/xx_yy_solve-1097929.out
logs/xx_yy_apply-1097930.out
*** Error *** Error in data selection specification: MSSelectionNullSelection : The selected table has zero rows.
(The same error repeated another 23 times)
</code></pre></div></div>

<p>This error likely corresponds to empty sub-MS(s) with data completely flagged out, which give a thread nothing to do for whichever CASA tasks are being called.</p>

<h5 id="20-rebuild-your-config-file-without-verbose-mode">20. Rebuild your config file without verbose mode</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -B -C tutorial_config.txt -M 1491550051.mms</code></p>

<p>This way we reset the list of scripts in our config file, and set <code class="highlighter-rouge">verbose=False</code> and <code class="highlighter-rouge">submit=False</code>. We will manually remove the scripts we already ran in <a href="#23-edit-submit_pipelinesh">step 23</a>, so leave the <code class="highlighter-rouge">scripts</code> parameter as is.</p>

<h5 id="21-edit-your-config-file">21. Edit your config file</h5>

<p>Edit <code class="highlighter-rouge">tutorial_config.txt</code> to update the reference antenna to what <code class="highlighter-rouge">calc_refant.py</code> found as the best reference antenna. If you’ve forgotten that was, view it in <code class="highlighter-rouge">jobScripts/tutorial_config_*.txt</code> (antenna 7). We don’t need to update <code class="highlighter-rouge">badants</code> as only <code class="highlighter-rouge">flag_round_1.py</code> uses this parameter, which we will not be running.</p>

<h5 id="22-run-the-pipeline-using-your-updated-config-file">22. Run the pipeline using your updated config file</h5>

<p><code class="highlighter-rouge">processMeerKAT.py -R -C tutorial_config.txt</code></p>

<p>Since we have set <code class="highlighter-rouge">verbose=False</code> and <code class="highlighter-rouge">submit=False</code>, the pipeline will not yet run, and you should see simplified output like the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2019-02-28 11:47:20,011 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again.
2019-01-16 20:30:00,180 INFO: Master script "submit_pipeline.sh" written, but will not run.
</code></pre></div></div>

<h5 id="23-edit-submit_pipelinesh">23. Edit <code class="highlighter-rouge">submit_pipeline.sh</code></h5>

<p>You will see in <code class="highlighter-rouge">submit_pipeline.sh</code> that each sbatch job is submitted on its own line, and that the job ID is extracted. Remove everything from <code class="highlighter-rouge">#validate_input.sbatch</code> to one line before <code class="highlighter-rouge">#flag_round_2.sbatch</code>, so it looks like the following</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cp </span>tutorial_config.txt .config.tmp

<span class="c">#flag_round_2.sbatch</span>
<span class="nv">IDs</span><span class="o">=</span><span class="k">$(</span>sbatch flag_round_2.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#setjy.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>setjy.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#xy_yx_solve.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>xy_yx_solve.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#xy_yx_apply.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>xy_yx_apply.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#split.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>split.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#quick_tclean.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>quick_tclean.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#plot_solutions.sbatch</span>
IDs+<span class="o">=</span>,<span class="k">$(</span>sbatch <span class="nt">-d</span> afterok:<span class="nv">$IDs</span> <span class="nt">--kill-on-invalid-dep</span><span class="o">=</span><span class="nb">yes </span>plot_solutions.sbatch | <span class="nb">cut</span> <span class="nt">-d</span> <span class="s1">' '</span> <span class="nt">-f4</span><span class="k">)</span>

<span class="c">#Output message and create jobScripts directory</span>
<span class="nb">echo </span>Submitted sbatch <span class="nb">jobs </span>with following IDs: <span class="nv">$IDs</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> jobScripts
   <span class="nb">.</span>
   <span class="nb">.</span>
   <span class="nb">.</span>
</code></pre></div></div>

<p><strong>Note the first line has been edited to replace <code class="highlighter-rouge">+=,</code> with <code class="highlighter-rouge">=</code> and remove <code class="highlighter-rouge">-d afterok:$IDs --kill-on-invalid-dep=yes</code>, since it does not have any dependencies.</strong></p>

<h5 id="24-run-submit_pipelinesh">24. Run <code class="highlighter-rouge">./submit_pipeline.sh</code></h5>

<p>Again, we see simplified output</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Submitted sbatch jobs with following IDs: 1097948,1097949,1097950,1097951,1097952,1097953,1097954
Run killJobs.sh to kill all the jobs.
Run summary.sh to view the progress.
Run findErrors.sh to find errors (after pipeline has run).
Run displayTimes.sh to display start and end timestamps (after pipeline has run).
</code></pre></div></div>

<p>These job IDs comprise the new pipeline run we’ve just launched. So now <code class="highlighter-rouge">./summary.sh</code> will display <code class="highlighter-rouge">sacct</code> for the new job IDs, similar to the following:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          JobID         JobName  Partition    Elapsed NNodes NTasks NCPUS  MaxDiskRead MaxDiskWrite             NodeList   TotalCPU      State ExitCode
--------------- --------------- ---------- ---------- ------ ------ ----- ------------ ------------ -------------------- ---------- ---------- --------
1097948         flag_round_2          Main   00:01:49      2            8                                slwrk-[013,020]   00:00:00    RUNNING      0:0
1097948.0       orted                        00:01:45      1      1     1                                      slwrk-020   00:00:00    RUNNING      0:0
1097949         setjy                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097950         xy_yx_solve           Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
1097951         xy_yx_apply           Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097952         split                 Main   00:00:00      2            8                                  None assigned   00:00:00    PENDING      0:0
1097953         quick_tclean          Main   00:00:00      2           64                                  None assigned   00:00:00    PENDING      0:0
1097954         plot_solutions        Main   00:00:00      1            1                                  None assigned   00:00:00    PENDING      0:0
</code></pre></div></div>

<p>The 4 new ancillary (bash) jobScripts will also correspond to these 7 new job IDs. If you want to see the output from the job scripts referring to the old pipeline runs, don’t worry, they’re still in the <code class="highlighter-rouge">jobScripts</code> directory with an older timestamp in the filename. Only the symlink in your working directory has been updated.</p>

<p>Wait until the run finishes before step 25. You may want to come back later, as it takes ~1.5 hours.</p>

<h5 id="25-view-the-pipeline-output">25. View the pipeline output</h5>

<p>After this pipeline run has completed, viewing the output of <code class="highlighter-rouge">./displayTimes.sh</code> shows this run took ~1.5 hours, including ~25 minutes for quick-look imaging all fields, and ~40 minutes for plotting (a <a href="/docs/processMeerKAT/Release-Notes#known-issues">known issue</a>).</p>

<p>These new tasks follow the second step of a two step calibration process that is summarised on <a href="/docs/processMeerKAT/calibration-in-processmeerkat">this page</a>.</p>

<p>After <code class="highlighter-rouge">split.py</code> has run, you will see three new files</p>

<p><code class="highlighter-rouge">1491550051.0252-712.mms 1491550051.0408-65.mms 1491550051.DEEP_2_off.mms</code></p>

<p>This corresponds to the data split out from <code class="highlighter-rouge">1491550051.mms</code>, for the bandpass/flux calibrator (<code class="highlighter-rouge">0408-65</code>), the phase calibrator (<code class="highlighter-rouge">0252-712</code>), and the science target (<code class="highlighter-rouge">DEEP_2_off</code>).</p>

<h5 id="26-view-the-images-in-the-images-directory">26. View the images in the <code class="highlighter-rouge">images</code> directory</h5>

<p><code class="highlighter-rouge">quick_tclean.py</code> creates quick-look images (i.e. with no selfcal, w-projection, thresholding, no multiscale, etc) with robust weighting 0, for all fields specified in the config file, creating 512x512 images of the calibrator fields, and 2048x2048 images of the target field(s), both with 2 arcsec pixel sizes. For data with &gt; 100 MHz bandwidth, two taylor terms are used, otherwise the ‘clark’ deconvolver is used.</p>

<p>You can view the images by connecting to a fat node (e.g. <code class="highlighter-rouge">racetrack.idia.ac.za</code> - also ensure X-forwarding is enabled) and launching ds9 or CASA viewer, respectively with the syntax (replace <code class="highlighter-rouge">/scratch/users/your_username/tutorial</code> below):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>singularity exec /idia/software/containers/sourcefinding_py3.simg ds9 /scratch/users/your_username/tutorial/images/*fits
singularity exec /idia/software/pipelines/casameer-5.4.1.xvfb.simg casa --nologger --log2term -c "viewer(infile='/scratch/users/your_username/tutorial/images/1491550051_DEEP_2_off.im.image.tt0/'); raw_input()"
</code></pre></div></div>

<p>Here’s what your images of the flux calibrator (<code class="highlighter-rouge">1934-638</code>) and target (<code class="highlighter-rouge">DEEP_2_off</code>) should look like.</p>

<p><img src="/assets/DEEP2_image.png" alt="DEEP2_image" /></p>

<p>Since we imaged a snapshot 16-dish MeerKAT observation using the old ROACH-2 correlator, with an on source time of ~20 minutes, we do not get very good image quality. Below is a more typical image produced by <code class="highlighter-rouge">quick_tclean.py</code> for a 64-dish observation using the SKARAB correlator, spanning ~8 hours, and only 10 MHz bandwidth.</p>

<p><img src="/assets/64-dish-image.png" alt="64-dish-image" /></p>

<h5 id="27-view-the-figures-in-plots-directory">27. View the figures in <code class="highlighter-rouge">plots</code> directory</h5>

<p>The last script that runs is <code class="highlighter-rouge">plot_solutions.py</code>, which calls CASA task <code class="highlighter-rouge">plotms</code> to plot the calibration solutions for the bandpass calibrator and the phase calibrator, as well as plots of the corrected data to eyeball for RFI. Below are a few selected plots.</p>

<p><img src="/assets/bpass_freq_amp.png" alt="bpass_freq_amp" />
<img src="/assets/DEEP_2_off_freq_amp.png" alt="DEEP_2_off_freq_amp" />
<img src="/assets/DEEP_2_off_real_imag.png" alt="DEEP_2_off_real_imag" /></p>

<p><strong>That’s it! You have completed the tutorial! Now go forth and do some phenomenal MeerKAT science!</strong></p>

<h3 id="also-see">Also see</h3>

<ul>
  <li><a href="/docs/processMeerKAT/calibration-in-processmeerkat">Calibration in processMeerKAT</a></li>
  <li><a href="/docs/processMeerKAT/Diagnosing-Errors">Diagnosing Errors</a></li>
  <li><a href="/docs/processMeerKAT/using-the-pipeline">Using the pipeline</a></li>
</ul>



          
        </div>
      </div>
    </div>
  </div>

</body>
</html>
