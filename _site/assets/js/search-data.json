{
  "1": {
    "id": "1",
    "title": "Calibration in ProcessMeerKAT",
    "content": "processMeerKAT implements a CASA based wide-band full Stokes calibration pipeline (in the linear basis). Broadly, the pipeline aims to “do the right thing” and by keeping the steps as general as possible we believe that there should be no need for fine tuning in order to obtain a well calibrated dataset. The pipeline is implemented as a series of SLURM sbatch scripts that in turn call CASA scripts. The scripts are separated out to make optimal use of MPI, by splitting out sections that can be run in parallel (via mpicasa and SLURM) and sections that do not take advantage of parallel architectures. The logical steps are: Input validation : This script performs a few basic validity checks, on the default config file, and on the input MS. the existence of the input MS, and the data types of the inputs specified in the config file are all verified before the pipeline continues to the next steps. If reference antenna calculation is not requested, a simple check is performed to verify that the input reference antenna exists in the MS. Otherwise, the following paragraph describes the details of reference antenna calculation. Reference antenna calculation : If the calcrefant parameter in the config file is set to True, then this script is executed. The algorithm works by calculating the median and standard deviation over all the visibility amplitudes for a given antenna, and iterates over every antenna in the array. Any outlier antennas, in the top 2 and bottom 5 percentile of this distribution are then flagged. The reference antenna is selected to be the un-flagged antenna with the smallest visibility rms. Data partition : The input measurement set (MS) is partitioned into a multi-measurement set (MMS) using the CASA task partition. This task splits up the main MS into smaller SUBMSs that are individual units of a larger logical MMS. The number of SUBMSs created are equal to the number of scans in the input MS. Partitioning the data in this manner allows for more efficient use of computation while using MPI, since each SUBMS can be independently operated on by different MPI workers. Flagging (round 1) : The first of two rounds of pre-calibration flagging. If badfreqranges and badants are specified in the config file, they are flagged. These lists are also allowed to be empty. Following that the data are clipped at the level of 50 Jy to eliminate the strongest RFI and the tfcrop algorithm is run independently on the primary and secondary calibrators and the target(s). setjy : The setjy task is run on the specified primary calibrators - this step is run once each before the first and second rounds of calibration. Parallel hand calibration : Standard delay, bandpass and gain calibration is run on the data, in order to obtain better statistics for a second round of flagging. Flagging (round 2) : Similar to the first round, the tfcrop algorithm is run independently on the primary and secondary calibrator and the target(s). The thresholds are lower than the first round as the algorithm is now operating on calibrated data. Cross hand calibration : The cross hand calibration recipe broadly follows the CASA guide for polarisation calibration in the linear basis. The previous round of calibration is cleared, and a new set of bandpass, delay and parallel hand gains are computed. Using the CASA helper routine qufromgain, the Q and U values of the secondary calibrator are computed, and are then used to solve for the frequency dependent leakages and XY calibration (i.e., “Dflls” and “XYf” calibration in polcal). The fluxes are then bootstrapped from the primary calibrator to the other fields specified in the config file. If the same source is specified as both the flux and secondary calibrator, no bootstrapping is performed as the time-dependent gain solutions should be correctly scaled to the fluxes specified in setjy. Splitting out calibrated data : Finally the calibrated data are averaged down in time and frequency by the amount specified in the config file, and the target(s) and calibrators are split out into separate MMSs for further imaging/processing. Detailed description What follows is a more detailed description of each of the steps described above, where applicable. Flagging (round 1) : If a list of bad frequency ranges and bad antennas is specified, those are flagged. Further, any autocorrelations are also flagged using mode=&#39;manual&#39; and autocorr=True in the flagdata parameters. Subsequently, flagdata is called on the calibrators and target sources with conservative limits to clip out the worst RFI. It also makes a single call to tfcrop to flag data at a 6 $ sigma$ limit. tfcrop in this case is preferred, since the as yet uncalibrated bandpass shape should be taken care of by fitting a piecewise polynomial across the band. setjy : By default, the ‘Perley-Butler 2010’ flux scale is used, since it is the only one which contains the popular southern calibrator PKS B1934-638. In case the calibrator J0408-6545 is present in the data, it is preferred. A broadband Stokes I model for J0408-6545 is used, via the manual mode of setjy.",
    "url": "http://localhost:4000/docs/processMeerKAT/Calibration-in-processMeerKAT/",
    "relUrl": "/docs/processMeerKAT/Calibration-in-processMeerKAT/"
  },
  "2": {
    "id": "2",
    "title": "DEEP 2 Tutorial",
    "content": "DEEP 2 Tutorial This tutorial walks you through running the various steps of the pipeline for a single DEEP 2 dataset, which is a 16 dish, 4k-mode MeerKAT observation of a random patch of sky, 11 GB in size. To begin, ssh into the ilifu cluster (slurm.ilifu.ac.za), and create a working directory somewhere on the filesystem (e.g. /ceph/pipelines/your_username/tutorial/). 1. Source setup.sh, which will add to your PATH and PYTHONPATH source /data/exp_soft/pipelines/master/setup.sh 2. Build a config file, using verbose mode, and pointing to the DEEP 2 dataset processMeerKAT.py -B -C tutorial_config.txt -M /data/projects/deep/1491550051.ms -v After some initial debug output, you should get the following output, with different timestamps 2019-02-28 02:36:14,421 INFO: Extracting field IDs from measurement set &quot;/data/projects/deep/1491550051.ms&quot; using CASA. 2019-02-28 02:36:14,422 DEBUG: Using the following command: srun --nodes=1 --ntasks=1 --time=10 --mem=4GB --partition=Main singularity exec /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg casa --nologger --nogui --nologfile -c /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/get_fields.py -B -M /data/projects/deep/1491550051.ms -C tutorial_config.txt -N 8 -t 4 . . . 2019-02-28 02:37:39,788 WARNING: The number of threads (8 node(s) x 4 task(s) = 32) is not ideal compared to the number of scans (12) for &quot;/data/projects/deep/1491550051.ms&quot;. 2019-02-28 02:37:39,788 WARNING: Config file has been updated to use 2 node(s) and 4 task(s) per node. 2019-02-28 02:37:39,788 INFO: For the best results, update your config file so that nodes x tasks per node = 7. 2019-02-28 02:37:40,045 INFO: Multiple fields found with intent &quot;CALIBRATE_FLUX&quot; in dataset &quot;/data/projects/deep/1491550051.ms&quot; - [0 1]. 2019-02-28 02:37:40,110 WARNING: Only using field &quot;0&quot; for &quot;fluxfield&quot;, which has the most scans (1). 2019-02-28 02:37:40,110 WARNING: Putting extra fields with intent &quot;CALIBRATE_FLUX&quot; in &quot;targetfields&quot; - [1] 2019-02-28 02:37:40,111 INFO: Multiple fields found with intent &quot;CALIBRATE_BANDPASS&quot; in dataset &quot;/data/projects/deep/1491550051.ms&quot; - [0 1]. 2019-02-28 02:37:40,111 WARNING: Only using field &quot;0&quot; for &quot;bpassfield&quot;, which has the most scans (1). 2019-02-28 02:37:40,112 INFO: Multiple fields found with intent &quot;CALIBRATE_PHASE&quot; in dataset &quot;/data/projects/deep/1491550051.ms&quot; - [1 2]. 2019-02-28 02:37:40,112 WARNING: Only using field &quot;2&quot; for &quot;phasecalfield&quot;, which has the most scans (5). 2019-02-28 02:37:40,123 INFO: [fields] section written to &quot;tutorial_config.txt&quot;. Edit this section to change field IDs (comma-seperated string for multiple IDs). 2019-02-28 02:37:41,990 INFO: Config &quot;tutorial_config.txt&quot; generated. This calls CASA via the default singularity container without writing log files, and runs get_fields.py. It calls srun, requesting only 1 node, 1 task, 4 GB of memory, and a 10 minute time limit, to increase the likelihood of jumping to the top of the queue. The purpose of this call is to extract the field IDs corresponding to our different targets, and check the nodes and tasks per node against the number of scans, each of which is handled by a thread (see section 3). The output statements with DEBUG correspond to those output during verbose mode. The warnings display when multiple fields are present with the same intent, but only one is extracted, corresponding to the field with the most scans. In this case the extras are moved to targetfields (i.e. for applying calibration and imaging). 3. View the config file created, which has the following contents: [crosscal] minbaselines = 4 # Minimum number of baselines to use while calibrating specavg = 1 # Number of channels to average after calibration (during split) timeavg = &#39;8s&#39; # Time interval to average after calibration (during split) keepmms = True # Output MMS (True) or MS (False) during split spw = &#39;0:860~1700MHz&#39; # Spectral window / frequencies to extract for MMS calcrefant = True # Calculate reference antenna in program (overwrites &#39;refant&#39;) refant = &#39;m005&#39; # Reference antenna name / number standard = &#39;Perley-Butler 2010&#39; # Flux density standard for setjy badants = [] # List of bad antenna numbers (to flag) badfreqranges = [ &#39;944~947MHz&#39;, # List of bad frequency ranges (to flag) &#39;1160~1310MHz&#39;, &#39;1476~1611MHz&#39;, &#39;1670~1700MHz&#39;] [slurm] nodes = 2 ntasks_per_node = 4 plane = 2 mem = 236 partition = &#39;Main&#39; time = &#39;12:00:00&#39; submit = False container = &#39;/data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg&#39; mpi_wrapper = &#39;/data/exp_soft/pipelines/casa-prerelease-5.3.0-115.el7/bin/mpicasa&#39; name = &#39;&#39; verbose = True scripts = [(&#39;validate_input.py&#39;, False, &#39;&#39;), (&#39;partition.py&#39;, True, &#39;&#39;), (&#39;calc_refant.py&#39;, False, &#39;&#39;), (&#39;flag_round_1.py&#39;, True, &#39;&#39;), (&#39;setjy.py&#39;, True, &#39;&#39;), (&#39;xx_yy_solve.py&#39;, False, &#39;&#39;), (&#39;xx_yy_apply.py&#39;, True, &#39;&#39;), (&#39;flag_round_2.py&#39;, True, &#39;&#39;), (&#39;setjy.py&#39;, True, &#39;&#39;), (&#39;xy_yx_solve.py&#39;, False, &#39;&#39;), (&#39;xy_yx_apply.py&#39;, True, &#39;&#39;), (&#39;split.py&#39;, True, &#39;&#39;), (&#39;quick_tclean.py&#39;, True, &#39;&#39;), (&#39;plot_solutions.py&#39;, False, &#39;&#39;)] [data] vis = &#39;/data/projects/deep/1491550051.ms&#39; [fields] bpassfield = &#39;0&#39; fluxfield = &#39;0&#39; phasecalfield = &#39;2&#39; targetfields = &#39;3,1&#39; This config file contains four sections - crosscal, slurm, data, and fields. The fields IDs we just extracted, seen in section [fields], correspond to field 0 for the bandpass calibrator, field 0 for the total flux calibrator, field 2 for the phase calibrator, and fields 3 and 1 for the science targets (i.e. the DEEP 2 field + another calibrator). Only the target may have multiple fields. If a field isn’t found according to its intent, a warning is displayed, and the field for the total flux calibrator is selected. If the total flux calibrator isn’t present, the program will display an error and terminate. The SLURM parameters in section [slurm] correspond to those seen by running processMeerKAT.py -h. By default, for all threadsafe scripts (i.e. those with True in the scripts list), we use 8 nodes, 4 tasks per node (=32 threads), 236 GB of memory (per node), and plane=2 (which distributes four tasks onto one node before moving onto next node). During step 2, only 12 scans were found, and since partition.py partitions the data into one sub-measurement set (sub-MS) per scan, only 12 sub-MSs will exist in the multi-measurement set (see section 19). Assuming each observation has a phase calibrator bracketing each target scan, at most, 6 sub-MSs will be operated on at any given time, each handled by one thread, and a master thread. So we aim to have a limit of nscans+1+10% threads, with the 10% to account for the occasional thread that hangs. For this dataset, this limit is 7 threads, so get_fields.py attempts to match this number by using the specified number of tasks per node and increasing the node count from 1 until the number of threads is more than the limit, terminating at 2 nodes x 4 tasks per node = 8 threads. For script that aren’t threadsafe (i.e. those with False in the scripts list), we use a single node, and a single task per node. For both scripts that are threadsafe and those that aren’t, we use a single CPU per task, and explicitly export OMP_NUM_THREADS=1, since there is little evidence of a speedup with more than one CPU per task. However, for quick_tclean.py we use 4 CPUs per task. The cross-calibration parameters in section [crosscal] correspond to various CASA parameters passed into the calibration tasks that the pipeline used, each of which is documented in [[Calibration-in-processMeerKAT]]. By default all frequency ranges listed in badfreqranges, and all antenna numbers listed in badants, will be flagged out entirely. The third script the pipeline runs (calc_refant.py) will likely change the value of refant, and add a list of bad antennas to badant. 4. Run the pipeline using your config file processMeerKAT.py -R -C tutorial_config.txt You should get the following output, with different timestamps 2019-02-28 02:44:06,078 DEBUG: Copying &#39;tutorial_config.txt&#39; to &#39;.config.tmp&#39;, and using this to run pipeline. 2019-02-28 02:44:06,096 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again 2019-02-28 02:44:06,131 DEBUG: Wrote sbatch file &quot;validate_input.sbatch&quot; 2019-02-28 02:44:06,138 DEBUG: Wrote sbatch file &quot;partition.sbatch&quot; 2019-02-28 02:44:06,144 DEBUG: Wrote sbatch file &quot;calc_refant.sbatch&quot; 2019-02-28 02:44:06,150 DEBUG: Wrote sbatch file &quot;flag_round_1.sbatch&quot; 2019-02-28 02:44:06,156 DEBUG: Wrote sbatch file &quot;setjy.sbatch&quot; 2019-02-28 02:44:06,172 DEBUG: Wrote sbatch file &quot;xx_yy_solve.sbatch&quot; 2019-02-28 02:44:06,247 DEBUG: Wrote sbatch file &quot;xx_yy_apply.sbatch&quot; 2019-02-28 02:44:06,253 DEBUG: Wrote sbatch file &quot;flag_round_2.sbatch&quot; 2019-02-28 02:44:06,260 DEBUG: Wrote sbatch file &quot;setjy.sbatch&quot; 2019-02-28 02:44:06,267 DEBUG: Wrote sbatch file &quot;xy_yx_solve.sbatch&quot; 2019-02-28 02:44:06,273 DEBUG: Wrote sbatch file &quot;xy_yx_apply.sbatch&quot; 2019-02-28 02:44:06,279 DEBUG: Wrote sbatch file &quot;split.sbatch&quot; 2019-02-28 02:44:06,291 DEBUG: Wrote sbatch file &quot;quick_tclean.sbatch&quot; 2019-02-28 02:44:06,331 DEBUG: Wrote sbatch file &quot;plot_solutions.sbatch&quot; 2019-02-28 02:44:06,338 INFO: Master script &quot;submit_pipeline.sh&quot; written, but will not run. A number of sbatch files have now been written to your working directory, each of which corresponds to the python script in the list of scripts set by the scripts parameter in our config file. Our config file was copied to .config.tmp, which is the config file written and edited by the pipeline, which the user should not touch. A bash script called submit_pipeline.sh was written, which we will look at soon. However, this script was not run, since we set submit = False in our config file (you can change this in your config file, or by using option [-s --submit] when you build your config file with processMeerKAT.py). Lastly, a logs directory was created, which will store the log files from the SLURM output. 5. View validate_input.sbatch, which has the following contents: #!/bin/bash #SBATCH --nodes=1 #SBATCH --ntasks-per-node=1 #SBATCH --cpus-per-task=1 #SBATCH --mem=100GB #SBATCH --job-name=validate_input #SBATCH --distribution=plane=1 #SBATCH --output=logs/validate_input-%j.out #SBATCH --error=logs/validate_input-%j.err #SBATCH --partition=Main #SBATCH --time=12:00:00 export OMP_NUM_THREADS=1 srun singularity exec /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg casa --nologger --nogui --logfile logs/validate_input-${SLURM_JOB_ID}.casa -c /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/validate_input.py --config .config.tmp Since this script is not threadsafe, the job is called with srun, and is configured to run a single task on a single node, with 100 GB of memory. The last line shows the CASA call of the validate_input.py task, which will validate the parameters in the config file. 6. Run the first sbatch job sbatch validate_input.sbatch You should see the following output, corresponding to your SLURM job ID Submitted batch job 1097914 7. View your job in the SLURM queue squeue You will see something similar to the following, with other people’s jobs mixed into the queue. JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 1097914 Main validate jcollier R 0:13 1 slwrk-008 We can see the job with name validate was submitted to SLURM worker node 8, amongst a number of jobs in the main partition, the JupyterSpawner partition, and possible other partitions. Your job may list (Priority), which means it is too low a priority to be run at this point, or (Resources), which means it is waiting for resources to be made available. NOTE: You can view just your jobs with squeue -u your_username, an individual job with squeue -j 1097914, and just the jobs in the main partition with squeue -p Main. You can view which nodes are allocated, which are idle, which are mixed (i.e. partially allocated), and which are down in the main partition with sinfo -p Main. Often it is good idea to check this before selecting your SLURM parameters. 8. View partition.sbatch, which has the following contents: #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks-per-node=4 #SBATCH --cpus-per-task=1 #SBATCH --mem=236GB #SBATCH --job-name=partition #SBATCH --distribution=plane=2 #SBATCH --output=logs/partition-%j.out #SBATCH --error=logs/partition-%j.err #SBATCH --partition=Main #SBATCH --time=12:00:00 export OMP_NUM_THREADS=1 /data/exp_soft/pipelines/casa-prerelease-5.3.0-115.el7/bin/mpicasa singularity exec /data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg casa --nologger --nogui --logfile logs/partition-${SLURM_JOB_ID}.casa -c /data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/partition.py --config .config.tmp Here we see the same default SLURM parameters for threadsafe tasks, as discussed in section 3. We now use mpicasa as the mpi wrapper, since we are calling a threadsafe script partition.py, which calls CASA task partition, which partitions the data into several sub measurement sets (sub-MSs - see section 14 below) and selects only frequencies specified by your spectral window with parameter spw in your config file. 9. Submit your job and watch it in the queue sbatch partition.sbatch Submitted batch job 1097917 squeue -j 1097917 You will see something similar to the following, showing that 2 nodes are now being used (worker nodes 60 &amp; 61). JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 1097917 Main partitio jcollier R 0:22 2 slwrk-[060-061] Wait until the job completes, before step 10. 10. View the contents of 1491550051.mms. You should see two new files - 1491550051.mms and 1491550051.mms.flagversions, which corresponds to the data and flag data of a multi-measurement set (MMS). From now on, the pipeline operates on these data, rather than the . The same path to the original MS will remain in your config file under section [data], but each task will point to your MMS. Inside this MMS, you will find the same tables and metadata as in a normal MS, but you will also see a SUBMSS directory, which should have the following contents. 1491550051.mms.0000.ms 1491550051.mms.0004.ms 1491550051.mms.0008.ms 1491550051.mms.0001.ms 1491550051.mms.0005.ms 1491550051.mms.0009.ms 1491550051.mms.0002.ms 1491550051.mms.0006.ms 1491550051.mms.0010.ms 1491550051.mms.0003.ms 1491550051.mms.0007.ms 1491550051.mms.0011.ms These are the 12 sub-MSs, partitioned by this observation’s 12 scans of the various targets. If we now view the CASA log, you will find a bunch of junk output from mpicasa (often including nominal “errors”, sometimes severe), and 13 calls of partition, corresponding to 12 workers for your 12 sub-MSs, and one master process. Similarly, your standard output logs will contains 8 sets of output from CASA launching, corresponding to the 8 threads (i.e. 2 nodes x 4 tasks per node) and some junk output from mpicasa. Again, your standard error log should be empty. 11. Run calc_refant.sbatch and watch your submitted job sbatch calc_refant.sbatch watch sacct You will initially see something similar to the following JobID JobName Partition Account AllocCPUS State ExitCode - - - - - -- 1097917 partition Main b03-pipel+ 8 COMPLETED 0:0 1097917.bat+ batch b03-pipel+ 4 COMPLETED 0:0 1097917.0 orted b03-pipel+ 1 COMPLETED 0:0 1097918 calc_refa+ Main b03-pipel+ 1 RUNNING 0:0 1097918.0 singulari+ b03-pipel+ 1 RUNNING 0:0 sacct lists all recently submitted jobs and their status. If your job fails, it will list FAILED under State. However, please note jobs running mpicasa often state they have failed when they haven’t. Similarly, when jobs do genuinely fail, the pipeline may continue to run. Both of these are issues we are working to overcome. When your job completes, you will see something similar to the following JobID JobName Partition Account AllocCPUS State ExitCode - - - - - -- 1097917 partition Test02 b03-pipel+ 8 COMPLETED 0:0 1097917.bat+ batch b03-pipel+ 4 COMPLETED 0:0 1097917.0 orted b03-pipel+ 1 COMPLETED 0:0 1097918 calc_refa+ Main b03-pipel+ 1 COMPLETED 0:0 1097918.bat+ batch b03-pipel+ 1 COMPLETED 0:0 1097918.0 singulari+ b03-pipel+ 1 COMPLETED 0:0 Control-C to exit out of watch. 12. View the contents of your logs directory ls logs calc_refant-1097918.casa calc_refant-1097918.err calc_refant-1097918.out partition-1097917.casa partition-1097917.err partition-1097917.out validate_input-1097914.casa validate_input-1097914.err validate_input-1097914.out As specified in our sbatch file, standard out is written to logs/calc_refant-1097918.out, standard error is written to logs/calc_refant-1097918.err, and the CASA logs are written to logs/calc_refant-1097918.casa. Your standard output log and CASA log will have little of interest, but your standard error log will contain the following output: 2019-02-28 03:02:33,870 INFO: Flux field scan no: 1 2019-02-28 03:02:34,034 INFO: Antenna statistics on total flux calibrator 2019-02-28 03:02:34,035 INFO: (flux in Jy averaged over scans &amp; channels, and over all of each antenna&#39;s baselines) 2019-02-28 03:02:34,035 INFO: ant median rms 2019-02-28 03:03:10,900 INFO: All 8.92 275.02 2019-02-28 03:03:10,900 INFO: 7 8.10 199.94 (best antenna) 2019-02-28 03:03:10,900 INFO: 0 8.84 305.28 (1st good antenna) 2019-02-28 03:03:10,900 INFO: setting reference antenna to: 7 2019-02-28 03:03:10,900 INFO: Bad antennas: [5, 15] Here we see calc_refant.py has selected antenna 7 as the best reference antenna, which measures comparable amplitude for the total flux calibrator compared to antenna 0, but a lower RMS. It has also found antennas 5 and 15 to be bad enough to flag out. 13. View ant_stats.txt You should see the following contents, corresponding to the amplitude and RMS each of the antennas measure ant median rms 0 8.84 305.28 1 7.80 251.12 2 7.69 279.64 3 8.13 219.86 4 9.37 322.45 5 7.10 253.62 6 7.95 254.35 7 8.10 199.94 8 8.21 326.82 9 10.15 306.20 10 9.00 258.92 11 11.57 270.17 12 10.55 270.40 13 13.38 396.25 14 13.66 434.22 15 243.71 569.51 14. View .config.tmp You should now see refant = 7 and badants = [5, 15]. 15. Edit your config file to run the next steps Edit tutorial_config.txt to remove the first two and last six tuples in the scripts parameter, so it looks like the following: scripts = [(&#39;flag_round_1.py&#39;, True, &#39;&#39;), (&#39;setjy.py&#39;, True, &#39;&#39;), (&#39;xx_yy_solve.py&#39;, False, &#39;&#39;), (&#39;xx_yy_apply.py&#39;, True, &#39;&#39;)] Replace refant and badants with what was found by validate_input.py, and select the submit option, so it looks like the following: [crosscal] refant = 7 badants = [5, 15] 16. Run the pipeline using your config file processMeerKAT.py -R -C tutorial_config.txt You should see the following output, with different timestamps 2019-02-28 03:18:26,585 DEBUG: Copying &#39;tutorial_config.txt&#39; to &#39;.config.tmp&#39;, and using this to run pipeline. 2019-02-28 03:18:26,605 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again 2019-02-28 03:18:26,615 DEBUG: Wrote sbatch file &quot;flag_round_1.sbatch&quot; 2019-02-28 03:18:26,624 DEBUG: Wrote sbatch file &quot;setjy.sbatch&quot; 2019-02-28 03:18:26,631 DEBUG: Wrote sbatch file &quot;xx_yy_solve.sbatch&quot; 2019-02-28 03:18:26,639 DEBUG: Wrote sbatch file &quot;xx_yy_apply.sbatch&quot; 2019-02-28 03:18:26,647 INFO: Running master script &quot;submit_pipeline.sh&quot; Copying tutorial_config.txt to .config.tmp, and using this to run pipeline. Submitting flag_round_1.sbatch SLURM queue with following command: sbatch flag_round_1.sbatch Submitting setjy.sbatch SLURM queue with following command sbatch -d afterok:1097919 --kill-on-invalid-dep=yes setjy.sbatch Submitting xx_yy_solve.sbatch SLURM queue with following command sbatch -d afterok:1097919,1097920 --kill-on-invalid-dep=yes xx_yy_solve.sbatch Submitting xx_yy_apply.sbatch SLURM queue with following command sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch Submitted sbatch jobs with following IDs: 1097919,1097920,1097921,1097922 Run killJobs.sh to kill all the jobs. Run summary.sh to view the progress. Run findErrors.sh to find errors (after pipeline has run). Run displayTimes.sh to display start and end timestamps (after pipeline has run). As before, we see the sbatch files being written to our working directory. Since we set submit=True, submit_pipeline.sh has been run, and all output after that (without the timestamps) comes from this bash script. After the first job is run (sbatch flag_round_1.sbatch), each other job is run with a dependency on all previous jobs (e.g. sbatch -d afterok:1097919,1097920,1097921 --kill-on-invalid-dep=yes xx_yy_apply.sbatch). We can see this by calling squeue -u your_username, which shows those jobs (Dependency). submit_pipeline.sh then writes four job scripts, all of which are explained in the output, written to jobScripts with a timestamp appended to the filename, and symlinked from your working directory. findErrors.sh finds errors after this pipeline run has completed, overlooking all nominal MPI errors. These tasks follow the first step of a two-step calibration process that is summarised in [[Calibration-in-processMeerKAT]]. 17. Run ./summary.sh This script simply calls sacct for all jobs submitted within this pipeline run. You should get output similar to the following. JobID JobName Partition Elapsed NNodes NTasks NCPUS MaxDiskRead MaxDiskWrite NodeList TotalCPU State ExitCode - - -- -- - - -- 1097927 flag_round_1 Main 00:00:04 2 8 slwrk-[060-061] 00:00:00 RUNNING 0:0 1097927.0 orted 00:00:04 1 1 1 slwrk-061 00:00:00 RUNNING 0:0 1097928 setjy Main 00:00:00 2 8 None assigned 00:00:00 PENDING 0:0 1097929 xx_yy_solve Main 00:00:00 1 1 None assigned 00:00:00 PENDING 0:0 1097930 xx_yy_apply Main 00:00:00 2 8 None assigned 00:00:00 PENDING 0:0 Those PENDING are the jobs with dependencies. Once this pipeline run has completed, ./summary.sh should give output similar to the following. JobID JobName Partition Elapsed NNodes NTasks NCPUS MaxDiskRead MaxDiskWrite NodeList TotalCPU State ExitCode - - -- -- - - -- 1097927 flag_round_1 Main 00:08:25 2 8 slwrk-[060-061] 11:04.530 COMPLETED 0:0 1097927.batch batch 00:08:25 1 1 4 11759M 2971M slwrk-060 04:46.830 COMPLETED 0:0 1097927.0 orted 00:08:25 1 1 1 14493M 1084M slwrk-061 06:17.699 COMPLETED 0:0 1097928 setjy Main 00:06:18 2 8 slwrk-[060-061] 03:21.451 COMPLETED 0:0 1097928.batch batch 00:06:18 1 1 4 24722M 24575M slwrk-060 02:23.206 COMPLETED 0:0 1097928.0 orted 00:06:17 1 1 1 5779M 5655M slwrk-061 00:58.245 COMPLETED 0:0 1097929 xx_yy_solve Main 00:03:28 1 1 slwrk-066 01:59.767 COMPLETED 0:0 1097929.batch batch 00:03:28 1 1 1 0.22M 0.18M slwrk-066 00:00.068 COMPLETED 0:0 1097929.0 singularity 00:03:28 1 1 1 10275M 5M slwrk-066 01:59.699 COMPLETED 0:0 1097930 xx_yy_apply Main 00:06:30 2 8 slwrk-[060-061] 03:32.520 COMPLETED 0:0 1097930.batch batch 00:06:30 1 1 4 8237M 4228M slwrk-060 01:29.291 COMPLETED 0:0 1097930.0 orted 00:06:29 1 1 1 13386M 6554M slwrk-061 02:03.228 COMPLETED 0:0 18. View caltables directory The calibration solution tables have been written to caltables/1491550051.*, including bcal, gcal, fluxscale and kcal, corresponding to the calibration solutions for bandpass, complex gains, flux-scaled complex gains, and delays, respectively. 19. Run ./displayTimes.sh You should see output similar to the following, which shows this run took 24 minutes to complete, the longest of which was flagging for 8.5 minutes. logs/flag_round_1-1097927.casa 2019-02-28 01:32:37 2019-02-28 01:40:32 logs/setjy-1097928.casa 2019-02-28 01:41:02 2019-02-28 01:46:49 logs/xx_yy_solve-1097929.casa 2019-02-28 01:47:15 2019-02-28 01:50:22 logs/xx_yy_apply-1097930.casa 2019-02-28 01:50:47 2019-02-28 01:56:49 20. Run ./findErrors.sh logs/flag_round_1-1097927.out logs/setjy-1097928.out logs/xx_yy_solve-1097929.out logs/xx_yy_apply-1097930.out *** Error *** Error in data selection specification: MSSelectionNullSelection : The selected table has zero rows. (The same error repeated another 23 times) This error likely corresponds to empty sub-MS(s) with data completely flagged out, which give a worker node nothing to do for whichever CASA tasks are being called. 21. Rebuild your config file without verbose mode processMeerKAT.py -B -C tutorial_config.txt -M 1491550051.mms This way we reset the list of scripts in our config file, and set verbose=False and submit=False. We will manually remove the scripts we already ran in step [[23 #Run-the-pipeline-using-your-updated-config-file]], so leave the scripts parameter as is. 22. Edit your config file Edit tutorial_config.txt to update the reference antenna to what calc_refant.py found as the best reference antenna. If you’ve forgotten that was, view it in jobScripts/tutorial_config_*.txt (antenna 7). We don’t need to update badants as only flag_round_1.py uses this parameter, which we will not be running. 23. Run the pipeline using your updated config file processMeerKAT.py -R -C tutorial_config.txt Since we have set verbose=False and submit=False, the pipeline will not yet run, and you should see simplified output like the following: 2019-02-28 11:47:20,011 WARNING: Changing [slurm] section in your config will have no effect unless you [-R --run] again 2019-01-16 20:30:00,180 INFO: Master script &quot;submit_pipeline.sh&quot; written, but will not run. 24. Edit submit_pipeline.sh You will see in submit_pipeline.sh that each sbatch job is submitted on its own line, and that the job ID is extracted. Remove everything from #validate_input.sbatch to one line before #flag_round_2.sbatch, so it looks like the following #!/bin/bash cp tutorial_config.txt .config.tmp #flag_round_2.sbatch IDs=$(sbatch flag_round_2.sbatch | cut -d &#39; &#39; -f4) #setjy.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes setjy.sbatch | cut -d &#39; &#39; -f4) #xy_yx_solve.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes xy_yx_solve.sbatch | cut -d &#39; &#39; -f4) #xy_yx_apply.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes xy_yx_apply.sbatch | cut -d &#39; &#39; -f4) #split.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes split.sbatch | cut -d &#39; &#39; -f4) #quick_tclean.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes quick_tclean.sbatch | cut -d &#39; &#39; -f4) #plot_solutions.sbatch IDs+=,$(sbatch -d afterok:$IDs --kill-on-invalid-dep=yes plot_solutions.sbatch | cut -d &#39; &#39; -f4) #Output message and create jobScripts directory echo Submitted sbatch jobs with following IDs: $IDs mkdir -p jobScripts . . . Note the first line has been edited to replace +=, with = and remove -d afterok:$IDs --kill-on-invalid-dep=yes, since it does not have any dependencies. 25. Run ./submit_pipeline.sh Again, we see simplified output Submitted sbatch jobs with following IDs: 1097948,1097949,1097950,1097951,1097952,1097953,1097954 Run killJobs.sh to kill all the jobs. Run summary.sh to view the progress. Run findErrors.sh to find errors (after pipeline has run). Run displayTimes.sh to display start and end timestamps (after pipeline has run). These job IDs comprise the new pipeline run we’ve just launched. So now ./summary.sh will display sacct for the new job IDs, similar to the following: JobID JobName Partition Elapsed NNodes NTasks NCPUS MaxDiskRead MaxDiskWrite NodeList TotalCPU State ExitCode - - -- -- - - -- 1097948 flag_round_2 Main 00:01:49 2 8 slwrk-[013,020] 00:00:00 RUNNING 0:0 1097948.0 orted 00:01:45 1 1 1 slwrk-020 00:00:00 RUNNING 0:0 1097949 setjy Main 00:00:00 2 8 None assigned 00:00:00 PENDING 0:0 1097950 xy_yx_solve Main 00:00:00 1 1 None assigned 00:00:00 PENDING 0:0 1097951 xy_yx_apply Main 00:00:00 2 8 None assigned 00:00:00 PENDING 0:0 1097952 split Main 00:00:00 2 8 None assigned 00:00:00 PENDING 0:0 1097953 quick_tclean Main 00:00:00 2 64 None assigned 00:00:00 PENDING 0:0 1097954 plot_solutions Main 00:00:00 1 1 None assigned 00:00:00 PENDING 0:0 The 4 new ancillary (bash) jobScripts will also correspond to these 7 new job IDs. After this pipeline run has completed, viewing the output of ./displayTimes.sh shows this run took XX minutes. If you want to see the output from the job scripts referring to the old pipeline runs, don’t worry, they’re still in the jobScripts directory with an older timestamp in the filename. Only the symlink in your working directory has been updated. These new tasks follow the second step of a two step calibration process that is summarised on [[this page Calibration-in-processMeerKAT]]. After split.py has run, you will see three new files 1491550051.0252-712.mms 1491550051.0408-65.mms 1491550051.DEEP_2_off.mms This corresponds to the data split out from 1491550051.mms, for the bandpass/flux calibrator (0408-65), the phase calibrator (0252-712), and the science target (DEEP_2_off). 26. View the images in the images directory quick_tclean.py creates quicklook images (i.e. with no selfcal, w-projection, threadholding, no-multiscale, etc) with robust weighting 0, for all fields specified in the config file, creating 512x512 images of the calibrator fields, and 2048x2048 images of the target field(s), both with 2 arcsec pixel sizes. For data with &gt; 100 MHz bandwidth, two taylor terms are used, otherwise the ‘clark’ deconvolver is used. 27. View the figures in plots directory The last script that runs is plot_solutions.py, which calls CASA task plotms to plot the calibration solutions for the bandpass calibrator and the phase calibrator. This is the reason that xvfb-run is called, which runs a virtual X server to make use of the plotting libraries. Your plots should look like the following. That’s it! You have completed the tutorial! Now go forth and do some phenomenal MeerKAT science! Also see [Calibration in processMeerKAT(Calibration-in-processMeerKAT) [[SLURM and MPICASA SLURM-and-MPICASA]] [[Using the pipeline Using-the-pipeline]]",
    "url": "http://localhost:4000/docs/processMeerKAT/DEEP-2-Tutorial/",
    "relUrl": "/docs/processMeerKAT/DEEP-2-Tutorial/"
  },
  "3": {
    "id": "3",
    "title": "Using the Pipeline",
    "content": "Usage The usage can be seen by running processMeerKAT.py -h which gives usage: /data/exp_soft/pipelines/master/processMeerKAT/processMeerKAT.py [-h] [-M path] [-C path] [-N num] [-t num] [-P num] [-m num] [-p name] [-T time] [-S script threadsafe container] [-w path] [-c path] [-n unique] [-l] [-s] [-v] (-B | -R | -V) Process MeerKAT data via CASA measurement set. Version: 1.0 optional arguments: -h, --help show this help message and exit -M path, --MS path Path to measurement set. -C path, --config path Path to config file. -N num, --nodes num Use this number of nodes [default: 8; max: 35]. -t num, --ntasks-per-node num Use this number of tasks (per node) [default: 4; max: 128]. -P num, --plane num Distribute tasks of this block size before moving onto next node [default: 2; max: ntasks-per-node]. -m num, --mem num Use this many GB of memory (per node) for threadsafe scripts [default: 236; max: 236]. -p name, --partition name SLURM partition to use [default: &#39;Main&#39;]. -T time, --time time Time limit to use for all jobs, in the form d-hh:mm:ss [default: &#39;12:00:00&#39;]. -S script threadsafe container, --scripts script threadsafe container Run pipeline with these scripts, in this order, using this container (3rd value - empty string to default to [-c --container]). Is it threadsafe (2nd value)? -w path, --mpi_wrapper path Use this mpi wrapper when calling threadsafe scripts [default: &#39;/data/exp_soft/pipelines/casa- prerelease-5.3.0-115.el7/bin/mpicasa&#39;]. -c path, --container path Use this container when calling scripts [default: &#39;/data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg&#39;]. -n unique, --name unique Unique name to give this pipeline run (e.g. &#39;run1_&#39;), appended to the start of all job names. [default: &#39;&#39;]. -l, --local Build config file locally (i.e. without calling srun) [default: False]. -s, --submit Submit jobs immediately to SLURM queue [default: False]. -v, --verbose Verbose output? [default: False]. -B, --build Build config file using input MS. -R, --run Run pipeline with input config file. -V, --version Display the version of this pipeline and quit. Simple usage To get things working, source setup.sh, which will add to your $PATH and $PYTHONPATH (add this to your ~/.profile, for future use) source /data/exp_soft/pipelines/master/setup.sh To print the version of the pipeline, run processMeerKAT.py -V To build a config file, which the pipeline reads as input for how to process the data, run processMeerKAT.py -B -C myconfig.txt -M mydata.ms To run the pipeline, run processMeerKAT.py -R -C myconfig.txt This will create submit_pipeline.sh, which you can then run to submit all pipeline jobs to a SLURM queue: ./submit_pipeline.sh Display a summary of the submitted jobs ./summary.sh Kill the submitted jobs ./killJobs.sh If the pipeline crashes, or reports an error, find the error(s) by running (after the pipeline has run) ./findErrors.sh Once the pipeline has completed, display the start and end times of each job by running ./displayTimes.sh Detailed usage Build config file locally (e.g. on a fat node) using a custom SLURM configuration (nodes and tasks per node may be overwritten in your config file with something more appropriate by the end of the build step) processMeerKAT.py -l -B -C myconfig.txt -M mydata.ms -p Test02 -N 10 -t 8 -P 4 -m 100 -T 06:00:00 -n mydata_ Build config file using different MPI wrapper and container processMeerKAT.py -B -C myconfig.txt -M mydata.ms --mpi_wrapper /path/to/another/mpi/wrapper --container /path/to/another/container Build config file with different set of (python) scripts processMeerKAT.py -B -C myconfig.txt -S /absolute/path/to/my/script.py False /absolute/path/to/container.simg -S partition.py True &#39;&#39; -S relative/path/to/my/script.py True relative/path/to/container.simg -S flag_round_1.py True &#39;&#39; -S script_in_bash_PATH.py False container_in_bash_PATH.simg run_setjy.py True &#39;&#39; Run the pipeline immediately in verbose mode processMeerKAT.py -R -v -s -C myconfig.txt NOTE: All other command-line arguments passed into processMeerKAT.py when using option [-R --run] will have no effect, since the arguments are read from the config file at this point. Only options [-v --verbose] and [-C --config] will have any effect at this point. Config files The config file is where you set parameters affecting how you run the pipeline. The default config contains the following [crosscal] minbaselines = 4 # Minimum number of baselines to use while calibrating specavg = 1 # Number of channels to average after calibration (during split) timeavg = &#39;8s&#39; # Time interval to average after calibration (during split) spw = &#39;0:860~1700MHz&#39; # Spectral window / frequencies to extract for MMS calcrefant = True # Calculate reference antenna in program (overwrites &#39;refant&#39;) refant = &#39;m005&#39; # Reference antenna name / number standard = &#39;Perley-Butler 2010&#39; # Flux density standard for setjy badants = [] # List of bad antenna numbers (to flag) badfreqranges = [ &#39;944~947MHz&#39;, # List of bad frequency ranges (to flag) &#39;1160~1310MHz&#39;, &#39;1476~1611MHz&#39;, &#39;1670~1700MHz&#39;] [slurm] # See processMeerKAT.py -h for documentation nodes = 8 ntasks_per_node = 4 plane = 2 mem = 236 # Use this many GB of memory (per node) partition = &#39;Main&#39; # SLURM partition to use time = &#39;12:00:00&#39; submit = False container = &#39;/data/exp_soft/pipelines/casameer-5.4.1.xvfb.simg&#39; mpi_wrapper = &#39;/data/exp_soft/pipelines/casa-prerelease-5.3.0-115.el7/bin/mpicasa&#39; verbose = False scripts = [ (&#39;validate_input.py&#39;,False,&#39;&#39;), (&#39;partition.py&#39;,True,&#39;&#39;), (&#39;calc_refant.py&#39;,False,&#39;&#39;), (&#39;flag_round_1.py&#39;,True,&#39;&#39;), (&#39;setjy.py&#39;,True,&#39;&#39;), (&#39;xx_yy_solve.py&#39;,False,&#39;&#39;), (&#39;xx_yy_apply.py&#39;,True,&#39;&#39;), (&#39;flag_round_2.py&#39;,True,&#39;&#39;), (&#39;setjy.py&#39;,True,&#39;&#39;), (&#39;xy_yx_solve.py&#39;,False,&#39;&#39;), (&#39;xy_yx_apply.py&#39;,True,&#39;&#39;), (&#39;split.py&#39;,True,&#39;&#39;), (&#39;plot_solutions.py&#39;,False,&#39;&#39;), (&#39;quick_tclean.py&#39;,True,&#39;&#39;)] When the pipeline is run, the contents of your config file are copied to .config.tmp and each python script reads the parameters from this file as it is run. This way, the user cannot easily break the pipeline during the time it is running. This also means changing the [slurm] section in your config file will have no effect unless you once again run processMeerKAT.py -R. Selecting MS and fields IDs As previously stated, to build a config file, run processMeerKAT.py -B -C myconfig.txt -M mydata.ms This calls CASA and adds a [data] section to your config file, which points to your MS, and a [fields] section, which points to the field IDs you want to process as bandpass, total flux and phase calibrators, and science target(s). Only targets may have multiple fields separated by a comma, and all extra calibrator fields are appended as “targets”, to allow for solutions to be applied to them, and images to be made of them (see [[Release-Notes:-V1.0]]). The following is an example of what is appended to the bottom of your config file. [data] vis = &#39;/data/projects/deep/1497056411.ms&#39; [fields] bpassfield = &#39;0&#39; fluxfield = &#39;0&#39; phasecalfield = &#39;1&#39; targetfields = &#39;2&#39; You can edit your config file and change the field IDs. Inserting your own scripts Our design allows the user to insert their own scripts into the pipeline, along with or instead of our own scripts. All scripts are assumed to be written in python, with extension .py. They must either have hard-coded values for input such as the MS name, or be able to read the config file and extract the values (e.g. as in the main() function of most of our scripts). To insert your own scripts, either build a config file and edit the scripts argument to contain your list of scripts, or pass your scripts via command line during building your config file. For each script that is added, three arguments are needed The path to the script Whether the script is threadsafe (for MPI - i.e. it can use mpicasa) The path to the container with which to call the script - use ‘ ‘ for the default container The path to the scripts (and containers) can be an absolute path, a relative path, or in your bash path. If none of these exist, the script (or container) is assumed to be in the calibration scripts directory (/data/exp_soft/pipelines/master/processMeerKAT/cal_scripts/). Hence simply using partition.py will call the partition script in the calibration scripts directory. Adding scripts to config file Edit the scripts argument in your config file, which must be a list of lists/tuples. Adding scripts via command line Build a config file pointing to your scripts, each time appending the same three arguments (listed above): processMeerKAT.py -B -C myconfig.txt -S /absolute/path/to/my/script.py False /absolute/path/to/container.simg -S partition.py True &#39;&#39; -S relative/path/to/my/script.py True relative/path/to/container.simg -S flag_round_1.py True &#39;&#39; -S script_in_bash_PATH.py False container_in_bash_path.simg run_setjy.py True &#39;&#39; An error will be raised if any of the scripts or containers aren’t found.",
    "url": "http://localhost:4000/docs/processMeerKAT/Using-The-Pipeline/",
    "relUrl": "/docs/processMeerKAT/Using-The-Pipeline/"
  },
  "4": {
    "id": "4",
    "title": "Access to IDIA Machines",
    "content": "Accessing IDIA Machines This page provides details on how to get access to the IDIA virtual machines. While this page is specific to the IDIA-Pipelines project, the details related to requesting access and connecting to a machine are identical. You can request access using the following form. In particular, please mention the team that you are a part of when you request access. This is extremely important, since it will help us provide you with access to the relevant project files. Joining the IDIA Pipelines Team Access to the IDIA-Pipeline resources can be arranged if you are part of the Pipelines Team. Please contact Bradley Frank (bradley@idia.ac.za) if you are interested in joining. Documentation and wiki access are provided through a GitHub project, so please sign-up to GitHub (if you haven’t already) and join the IDIA Pipelines repo as a contributor. Access There are a pool of IDIA machines that are available for usage. Please note that the machine names mentioned here are meant for usage by the IDIA-Pipelines team. In practice, we will provide you with a machine name after you’ve requested access. You can access IDIA machines via a Jupyter-Hub (preferred) or SSH (traditional). The URL usually corresponds to the name of the VM, and is served on the IDIA domain. For example, our helo node can be accessed via https://helo.idia.ac.za. Jupyter-Hub A Virtual Machine (VM) can be accessed online using your browser (Chrome/Firefox preferred). Simply type in the URL provided. You will be presented with a login window for the Jupyter-Hub. Use your previously generated (LDAP) username and password to access your account. SSH To SSH into an IDIA VM, you will need your SSH key. This is how you would SSH into helo with X-forwarding: $ ssh -XY -i /path/to/your/key.pem helo.idia.ac.za -l &lt;username&gt; Changing your Password You need to change your generic password as soon as possible. You can do this with the following command (one line on the prompt): $ ldappasswd -H ldap://10.102.4.109 -x -D &quot;cn=username,ou=users,dc=idia,dc=arc,dc=ac,dc=za&quot; -W -S -A Important: In the command above, you will need to change username to your username. You will then be prompted for passwords as follows: Twice for your current password (verification). Twice for your new password. Once for your LDAP password, which will be your old password. This is required to bind to the LDAP server to commit the change to your password. This is a little more involved then usual, because your credentials are not specific to a machine. Access on the cloud is coordinated on using the LDAP server – this is why you need to do the authenticate -&gt; enter new password -&gt; authorize/bind process to propagate your password to the server. This allows us to provide you with access to any machine provisioned for your project without having to remember a myriad of passwords. Incidentally, you can do this without ssh’ing into the machine – simply open up a terminal using the Jupyter-Hub and use this to change your password. Storage There are several storage areas available. Most (all) Pipelines machines will have the IDIA storage attached. This means that you will have access to your work and your data on any system that you’re logged into. Access to data is managed with Unix groups. Please take careful note of the following. /users/&lt;username&gt;/, where /users is a shared BeeGFS volume. /data/users/&lt;username&gt;/, where /data is a shared BeeGFS volume. This is the preferred space for you to store your longish term data products. /data/&lt;Project&gt; is a shared directory on BeeGFS for a project. You can fetch raw data from here. Please steer away from dumping data into this directory. /scratch/users/&lt;username&gt;/ is the shared working directory for , where `/scratch` is a BeeGFS volume). This is the preferred space for intermediate data products, e.g., you can use this space to do imaging. Setting up your own VM. Smaller VMs can be spun-up for (sub)-projects. Additionally, users will have to follow the aforementioned process to setup their accounts. Please use the Google form to design and Request a VM. GitHub There are two important GitHub resources that project members can use: IDIA-Pipelines Blog: This is the repo for this website, and there is an associated wiki for project members to share information. IDIA Containers: This is very important repository for the Singularity containers used at IDIA.",
    "url": "http://localhost:4000/docs/access/",
    "relUrl": "/docs/access/"
  },
  "5": {
    "id": "5",
    "title": "Singularity Containers",
    "content": "Singularity Containers At IDIA, astronomical software packages are provided and managed using Singularity containers. Containers are managed and built by our developers. If you have any questions/issues relating to containers, please send an email to support@ilifu.ac.za. Available Containers The most recent, stable versions of containers are available in /data/exp_soft/containers/. Some of these containers can be accessed via the Jupyter-Hub, but all of them can be accessed via the terminal (i.e., once you’ve ssh’d into an IDIA machine). Here are a few examples of the latest stable Singularity container builds that are available in /data/exp_soft/containers/: jupyter-casa-latest.simg Allows you to use CASA tasks via the Jupyter notebook. Note that visualisation tools like plotms or viewer will not work on the notebook. casa-stable-5.3.0.simg Contains the CASA binaries for the 5.3.0. release. kern4.simg Contains all the software packages provided by the Kern repository. sourcefinding_py3.simg Builds of commonly used source finding packages, e.g., PyBDSF. Reporting a bug / Requesting Software Please send an email to support@ilifu.ac.za to report issues, or to request new containers, or for existing containers to be updated. Using Containers Shell You can access software in Singularity containers using two methods. Firstly, you can shell into the container. You will enter a shell which provides access to the software provided in that container: $ singularity shell /data/exp_soft/containers/casa-stable-5.3.0.simg Singularity: Invoking an interactive shell within container... Singularity casa-stable-5.3.0.simg:~&gt; casa --nologger --log2term --nogui ========================================= The start-up time of CASA may vary depending on whether the shared libraries are cached or not. ========================================= IPython 5.1.0 -- An enhanced Interactive Python. CASA 5.3.0-143 -- Common Astronomy Software Applications 2018-08-07 12:37:28 INFO ::casa CASA Version 5.3.0-143 --&gt; CrashReporter initialized. Enter doc(&#39;start&#39;) for help getting started with CASA... Using matplotlib backend: TkAgg CASA &lt;1&gt;: print &quot;Hello World&quot; Hello World Exec You can also pass a command to a container (using the exec argument), which then gets executed via the shell in that container. For example, here’s an illustration of how to use the exec argument to jump into an interactive CASA session: $ singularity exec /data/exp_soft/containers/casa-stable-5.3.0.simg casa --nologger --log2term --nogui ========================================= The start-up time of CASA may vary depending on whether the shared libraries are cached or not. ========================================= IPython 5.1.0 -- An enhanced Interactive Python. CASA 5.3.0-143 -- Common Astronomy Software Applications 2018-08-07 12:41:19 INFO ::casa CASA Version 5.3.0-143 --&gt; CrashReporter initialized. Enter doc(&#39;start&#39;) for help getting started with CASA... Using matplotlib backend: TkAgg CASA &lt;1&gt;: inp listobs --&gt; inp(listobs) # listobs :: List the summary of a data set in the logger or in a file vis = &#39;&#39; # Name of input visibility file (MS) selectdata = True # Data selection parameters field = &#39;&#39; # Selection based on field names or field index numbers. Default is all. spw = &#39;&#39; # Selection based on spectral-window/frequency/channel. antenna = &#39;&#39; # Selection based on antenna/baselines. Default is all. timerange = &#39;&#39; # Selection based on time range. Default is entire range. correlation = &#39;&#39; # Selection based on correlation. Default is all. scan = &#39;&#39; # Selection based on scan numbers. Default is all. intent = &#39;&#39; # Selection based on observation intent. Default is all. feed = &#39;&#39; # Selection based on multi-feed numbers: Not yet implemented array = &#39;&#39; # Selection based on (sub)array numbers. Default is all. uvrange = &#39;&#39; # Selection based on uv range. Default: entire range. Default units: meters. observation = &#39;&#39; # Selection based on observation ID. Default is all. verbose = True # Controls level of information detail reported. True reports more than False. listfile = &#39;&#39; # Name of disk file to write output. Default is none (output is written to logger only). listunfl = False # List unflagged row counts? If true, it can have significant negative performance impact. cachesize = 50 # EXPERIMENTAL. Maximum size in megabytes of cache in which data structures can be held. CASA &lt;2&gt;: The true utility of the exec argument is to execute commands non-interactively: $ singularity exec /data/exp_soft/containers/casa-stable-5.3.0.simg casa --nologger --log2term --nogui -c &quot;print &#39;Hello World&#39;&quot; ========================================= The start-up time of CASA may vary depending on whether the shared libraries are cached or not. ========================================= IPython 5.1.0 -- An enhanced Interactive Python. CASA 5.3.0-143 -- Common Astronomy Software Applications 2018-08-07 12:45:43 INFO ::casa CASA Version 5.3.0-143 --&gt; CrashReporter initialized. Hello World $ While the command may seem cumbersome, it is very useful when trying to build scripts that utilise several containers.",
    "url": "http://localhost:4000/docs/containers/",
    "relUrl": "/docs/containers/"
  },
  "6": {
    "id": "6",
    "title": "Home",
    "content": "IDIA Pipelines Welcome to the IDIA Pipelines Website. Here you’ll find help and documentation to help you do calibration and imaging of Radio Data Using the IDIA system. The IDIA Pipelines Team The team includes members from many of the MeerKAT Large Survey Projects. This list includes the active members who are working on the IDIA system, or the related software/algorithms: Jordan Collier Bradley Frank (Project Lead) Srikrishna Sekhar Russ Taylor Contact Email the project lead at bradley@idia.ac.za, or submit a ticket to our helpdesk: support@ilifu.ac.za.",
    "url": "http://localhost:4000/",
    "relUrl": "/"
  },
  "7": {
    "id": "7",
    "title": "processMeerKAT",
    "content": "The processMeerKAT software has been written to do calibration and imaging of MeerKAT interferometric data. Typical calibration and imaging of radio data comprises three steps: Initial or a priori calibration, which involves bootstrapping phase and flux gains from observations of reference calibrators. Self-calibration or a posteriori’ calibration, where the residual on-target errors are solved for by (iteratively) building a good representation of the field. 3rd Generation Calibration (3GC), aka post-selfcal, which deals with higher-order effects in the pursuit of high dynamic range imaging. This includes compensating for the primary beam and direction dependent effects. The processMeerKAT currently does full-polarisation a priori calibration on MeerKAT data, and includes automated flagging. processMeerKAT is written solely for the processing of data on IDIA’s SLURM cluster, but future revisions will allow you to run the software on any HPC platform. The main features of processMeerKAT are as follows: Is written in Python 3. Calibration algorithms only use CASA 5.4.X tasks and helper functions. ** Uses a purpose-built CASA Singularity container for parallel processing at IDIA, i.e, is fully thread-safe. Uses MPICASA to run parallel jobs over the cluster. Generates SBATCH files and ancillary helper scripts for processing. Please read the documentation to learn how to use the pipeline for your imaging data at IDIA.",
    "url": "http://localhost:4000/docs/processMeerKAT",
    "relUrl": "/docs/processMeerKAT"
  }
  
}
