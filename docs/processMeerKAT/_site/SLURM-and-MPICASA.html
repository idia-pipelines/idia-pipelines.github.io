<h1 id="parallel-casa-using-slurm-at-idia">Parallel CASA Using SLURM at IDIA</h1>

<p><strong>Note: For details on how to setup SLURM batch and interactive jobs on the ilifu system, please look at the <a href="https://docs.ilifu.ac.za/#/getting_started/submit_job_slurm">ilifu documentation</a>.</strong></p>

<p>This page deals with the specifics of using CASA in conjuction with the SLURM environment on the ilifu computing system.</p>

<p>SLURM is a resource and job management system that is available on many clusters. Jobs/tasks are typically submitted to the job management system, and are inserted into a job queue; the job is executed when the requested resources become available. SLURM is currently used with the IDIA cluster.</p>

<p>While SLURM Clusters provide the option to request and reserve resources to work in an interactive mode, its preferred to submit jobs to the queue to be run in a non-interactive way.</p>

<p>To run a CASA script in a non-interactive way in the SLURM cluster, you would use the following steps.</p>

<ol>
  <li>Write your CASA script.</li>
  <li>Write an associated SBATCH script for your job.</li>
  <li>Submit the script (i.e., your job) to the queue using <code class="highlighter-rouge">sbatch</code>.</li>
</ol>

<!---

_**The image below illustrates these different steps.**_

![Basic step-by-step guide on to use SLURM and MPICASA to run a CASA Script.](/assets/slurm-and-mpicasa.png)

--->

<h2 id="write-your-casa-script">Write your CASA Script</h2>
<p>CASA scripts are written in Python. An entire pipeline can be written in such a script, that includes flagging, initial calibration and imaging.</p>

<p>It is important to note that different CASA tasks use different schemes for parallelism, when writing your script. For example, <code class="highlighter-rouge">flagdata</code> parallelises by scan and is thus RAM intensive; <code class="highlighter-rouge">tclean</code> splits up the input data to occupy as many processes are are specified, and is this CPU &amp; RAM intensive.</p>

<p>Therefore, a single script that includes flagging and imaging could have sub-optimal usage of a cluster resources for some tasks, and optimal usage for others. Keep this in mind when writing your script.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vis = '/path/to/visibility.ms'
var1 = 'something'
var2 = 1e-3
casatask(vis=vis,
  var1=var1,
  var2=var2)

casatask2(vis=vis)
</code></pre></div></div>

<h2 id="write-your-sbatch-script">Write your SBATCH Script</h2>
<p>An SBATCH script is a bash script that wraps the relevant SLURM parameters needed for your script. Consult the following website for more details on how to use SBATCH:
https://slurm.schedmd.com/sbatch.html</p>

<p>Here’s an example of an SBATCH script that submits a TCLEAN job:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="c">#SBATCH -N 4-4</span>
<span class="c">#SBATCH --tasks-per-node 48</span>
<span class="c">#SBATCH -J tclean</span>
<span class="c">#SBATCH -m plane=8</span>
<span class="c">#SBATCH -o /path/to/stdout.log</span>
<span class="c">#SBATCH -e /path/to/stderr.log</span>

<span class="c">#Run the application:</span>
/path/to/casa-prerelease-5.3.0-115.el7/bin/mpicasa /usr/bin/singularity <span class="nb">exec</span> /path/to/casa/container.simg  <span class="s2">"casa"</span> <span class="nt">--nologger</span> <span class="nt">--log2term</span> <span class="nt">--nogui</span> <span class="nt">-c</span> tclean.py
</code></pre></div></div>

<p>You can find more details on how to use Singularity on ilifu on <a href="https://docs.ilifu.ac.za/#/getting_started/container_environments">their website</a>.</p>

<p>There are a few important SBATCH parameters to define:</p>

<ul>
  <li><code class="highlighter-rouge">--nodes</code> or <code class="highlighter-rouge">-N</code> specifies the node count, i.e., the nodes requested for the job.</li>
  <li><code class="highlighter-rouge">--tasks-per-node</code> specifies the number of parallel tasks to execute on each node.</li>
  <li><code class="highlighter-rouge">--mode</code> or <code class="highlighter-rouge">-m</code> specifies the mode in which the tasks are distributed to each node.
    <ul>
      <li>This parameter is useful for scripts that include flagging. Since flagging is parallelised by scan, the first node(s) could run out of RAM for a particular flagging job. This would lead to SLURM killing the offending task(s), hence killing the main job.</li>
      <li>There are two distribution modes that can be used to solve this problem. <code class="highlighter-rouge">plane=X</code> distributes X jobs at a time, in a round-robin fashion across nodes. The <code class="highlighter-rouge">cyclic</code> mode distributes single tasks at a time in a round-robin fashion across nodes.</li>
      <li><code class="highlighter-rouge">plane=X</code> or <code class="highlighter-rouge">cyclic</code> modes are useful for jobs that are RAM limited, i.e., when you need to use the aggregated RAM that’s in the total pool requested.</li>
    </ul>
  </li>
  <li>The <code class="highlighter-rouge">-J</code>, <code class="highlighter-rouge">-o</code> and <code class="highlighter-rouge">-e</code> parameters</li>
</ul>

<h3 id="more-about-slurm">More about SLURM</h3>
<p><a href="https://slurm.schedmd.com/overview.html">SLURM</a> is a workload manager that will distribute jobs across a specified cluster environment. It understands how to control an MPI-aware job via <code class="highlighter-rouge">mpirun</code> and hence also via <code class="highlighter-rouge">mpicasa</code>. In principle this means that SLURM should be able to schedule and manage a CASA job that is running across a cluster.</p>

<p>Following is a “practical” definition of some SLURM keywords that should help clarify how to best to allocate resources.</p>

<p><strong>task</strong> : A “task” by SLURM’s definition is what one would usually call a “process” on a regular computer. Similar to a process, a task has its own memory allocation that it does not share with other tasks. Each task is then operated on independently via MPI. This also means a more <em>fine-grained</em> parallelism can be employed per task, by using multiple threads (<em>e.g.</em> via openMP) to work on a single task.</p>

<p><strong>–cpus-per-task</strong> : Defines the number of CPUs to dedicate to a single task. If each task can take advantage of multiple threads, setting this value to more than one can speed things up further (<em>e.g.,</em> <code class="highlighter-rouge">tclean</code> in CASA is parallelised across openMP and MPI)</p>

<p><strong>–mem-per-cpu</strong> : The RAM dedicated to each CPU in the node. At the moment, the IDIA cluster is set to 4096MB per CPU. If a job is running out of memory, setting this to a larger value can help. Alternatively, as mentioned above if the task can take advantage of more threads, it may be preferable to set <code class="highlighter-rouge">--cpus-per-task</code> instead.</p>

<p><strong>-m/–distribution</strong> : This controls how the tasks are allocated across the requested nodes. The sbatch <code class="highlighter-rouge">man</code> page has a very good explanation on the various modes available.</p>

<hr />

<h3 id="notes-on-casa-tasks-and-parallelism">Notes on CASA Tasks and Parallelism</h3>

<p>Running CASA through SLURM requires calling CASA via <code class="highlighter-rouge">mpicasa</code>. CASA understands how to use <code class="highlighter-rouge">mpi</code> on tasks that are optimised for <code class="highlighter-rouge">mpi</code> (such as <code class="highlighter-rouge">flagdata</code>, <code class="highlighter-rouge">tclean</code>, <code class="highlighter-rouge">setjy</code>, and <code class="highlighter-rouge">applycal</code>) while operating as per usual on tasks that are not <code class="highlighter-rouge">mpi</code> aware (like <code class="highlighter-rouge">gaincal</code>). Ideally, the only change to an existing script would be to add a call to <code class="highlighter-rouge">partition</code> at the top. Below are some notes on tasks.</p>

<p><strong>partition</strong>: In order to run tasks (except tclean) across a cluster, the <code class="highlighter-rouge">partition</code> task needs to be called prior to running any other tasks. <code class="highlighter-rouge">partition</code>  <a href="https://casa.nrao.edu/casadocs/casa-5.4.1/uv-manipulation/data-partition">creates a multi-measurement set</a> (MMS) that is a collection of multiple SUBMS’s, each of which will be operated upon as a task in SLURM. By default CASA will split the MS along the spectral window (<code class="highlighter-rouge">spw</code>) axis, and across scans.</p>

<!--
The number of SUBMSes created can be specified in `partition`, however it seems that specifying a number larger than what CASA would decide leads to some strangeness with the metadata (and a failure of tasks that operate on the MMS).
-->

<p><strong>tclean</strong>: In order to run across a cluster, <code class="highlighter-rouge">parallel=True</code> should be specified in <code class="highlighter-rouge">tclean</code>. However, if <code class="highlighter-rouge">savemodel='modelcolumn'</code> is also specified, it triggers some kind of a race condition between the different nodes where they are competing for write access, and the task crashes. So setting <code class="highlighter-rouge">savemodel='virtual'</code> or <code class="highlighter-rouge">savemodel='none'</code> are the only options that work. Both the <code class="highlighter-rouge">makePSF</code> step and the major cycles of deconvolution are openMP aware, and can exploit additional resources specified via <code class="highlighter-rouge">--cpus-per-task</code> in the SLURM <code class="highlighter-rouge">sbatch</code> file.</p>
